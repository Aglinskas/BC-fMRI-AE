{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c3c5e532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mmfs1/data/aglinska/BC-fMRI-AE/Notebooks'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "18aa73f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 27 14:45:03 EDT 2022\n"
     ]
    }
   ],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f913ca19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.3 ms, sys: 5.72 ms, total: 7.02 ms\n",
      "Wall time: 23.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow' from '/data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/__init__.py'>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "from umap import UMAP\n",
    "\n",
    "import os\n",
    "from datetime import datetime; now = datetime.now\n",
    "tqdm = partial(tqdm, position=0, leave=True) \n",
    "\n",
    "\n",
    "from importlib import reload\n",
    "import helper_funcs;reload(helper_funcs);from helper_funcs import *\n",
    "del helper_funcs\n",
    "import make_models;reload(make_models);from make_models import *\n",
    "del make_models\n",
    "\n",
    "from IPython import display\n",
    "import sys\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "import shutil\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "reload(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d0d5a140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVAE_2022-03-25 18:28:49.469238\n",
      "../Assets/tf_weights/CVAE_2022-03-25 18:28:49.469238\n"
     ]
    }
   ],
   "source": [
    "analysis_name = 'CVAE_2022-03-25 18:28:49.469238'\n",
    "save_dir = os.path.join('../Assets/tf_weights',analysis_name)\n",
    "print(analysis_name)\n",
    "print(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2aa9b4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SFARI_ID</th>\n",
       "      <th>BIDS_ID</th>\n",
       "      <th>site</th>\n",
       "      <th>age_years</th>\n",
       "      <th>latest_clinical_asd_dx</th>\n",
       "      <th>svip_diagnosis_m1</th>\n",
       "      <th>family_type</th>\n",
       "      <th>genetic_status_16p</th>\n",
       "      <th>ados_module</th>\n",
       "      <th>...</th>\n",
       "      <th>measure_type</th>\n",
       "      <th>mother</th>\n",
       "      <th>relationship_to_iip</th>\n",
       "      <th>svip_neuro_exam.background.head_circum</th>\n",
       "      <th>svip_neuro_exam.background.head_circum_perc</th>\n",
       "      <th>svip_neuro_exam.background.head_circum_z_score</th>\n",
       "      <th>svip_neuro_exam.measure.eval_age_months</th>\n",
       "      <th>svip_neuro_exam.measure.measure_type</th>\n",
       "      <th>dur_run1</th>\n",
       "      <th>dur_run2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14702.x3</td>\n",
       "      <td>sub-001</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>non-spectrum-dx</td>\n",
       "      <td>16p-deletion</td>\n",
       "      <td>deletion</td>\n",
       "      <td>ados-2</td>\n",
       "      <td>...</td>\n",
       "      <td>diagnosis-summary</td>\n",
       "      <td>14702-x1</td>\n",
       "      <td>Initially identified proband</td>\n",
       "      <td>55.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.18</td>\n",
       "      <td>119.0</td>\n",
       "      <td>svip-neuro-exam</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>14705.x14</td>\n",
       "      <td>sub-003</td>\n",
       "      <td>50</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "      <td>no-diagnosis</td>\n",
       "      <td>16p-duplication</td>\n",
       "      <td>duplication</td>\n",
       "      <td>ados-4</td>\n",
       "      <td>...</td>\n",
       "      <td>diagnosis-summary</td>\n",
       "      <td>14705-x1</td>\n",
       "      <td>Mother</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405.0</td>\n",
       "      <td>svip-neuro-exam</td>\n",
       "      <td>4.45</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>14714.x18</td>\n",
       "      <td>sub-006</td>\n",
       "      <td>60</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>no-diagnosis</td>\n",
       "      <td>16p-deletion</td>\n",
       "      <td>deletion</td>\n",
       "      <td>ados-4</td>\n",
       "      <td>...</td>\n",
       "      <td>diagnosis-summary</td>\n",
       "      <td>14714-x12</td>\n",
       "      <td>Initially identified proband</td>\n",
       "      <td>55.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.49</td>\n",
       "      <td>249.0</td>\n",
       "      <td>svip-neuro-exam</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>14723.x17</td>\n",
       "      <td>sub-009</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>non-spectrum-dx</td>\n",
       "      <td>16p-duplication</td>\n",
       "      <td>duplication</td>\n",
       "      <td>ados-2</td>\n",
       "      <td>...</td>\n",
       "      <td>diagnosis-summary</td>\n",
       "      <td>14723-x9</td>\n",
       "      <td>Initially identified proband</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>svip-neuro-exam</td>\n",
       "      <td>5.20</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>14725.x46</td>\n",
       "      <td>sub-011</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>no-diagnosis</td>\n",
       "      <td>16p-duplication</td>\n",
       "      <td>duplication</td>\n",
       "      <td>ados-3</td>\n",
       "      <td>...</td>\n",
       "      <td>diagnosis-summary</td>\n",
       "      <td>14725-x55</td>\n",
       "      <td>Cousin</td>\n",
       "      <td>49.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.35</td>\n",
       "      <td>120.0</td>\n",
       "      <td>svip-neuro-exam</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>201</td>\n",
       "      <td>15057.x1</td>\n",
       "      <td>sub-202</td>\n",
       "      <td>50</td>\n",
       "      <td>62</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-familial-control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.02</td>\n",
       "      <td>747.0</td>\n",
       "      <td>svip-neuro-exam</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>202</td>\n",
       "      <td>15060.x1</td>\n",
       "      <td>sub-203</td>\n",
       "      <td>50</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-familial-control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.42</td>\n",
       "      <td>338.0</td>\n",
       "      <td>svip-neuro-exam</td>\n",
       "      <td>5.10</td>\n",
       "      <td>3.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>204</td>\n",
       "      <td>15071.x1</td>\n",
       "      <td>sub-205</td>\n",
       "      <td>60</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-familial-control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.67</td>\n",
       "      <td>335.0</td>\n",
       "      <td>svip-neuro-exam</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>206</td>\n",
       "      <td>15083.x5</td>\n",
       "      <td>sub-207</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>non-spectrum-dx</td>\n",
       "      <td>16p-deletion</td>\n",
       "      <td>deletion</td>\n",
       "      <td>ados-3</td>\n",
       "      <td>...</td>\n",
       "      <td>diagnosis-summary</td>\n",
       "      <td>15083-x3</td>\n",
       "      <td>Initially identified proband</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.77</td>\n",
       "      <td>149.0</td>\n",
       "      <td>svip-neuro-exam</td>\n",
       "      <td>5.05</td>\n",
       "      <td>5.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>207</td>\n",
       "      <td>15090.x1</td>\n",
       "      <td>sub-208</td>\n",
       "      <td>50</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-familial-control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.42</td>\n",
       "      <td>170.0</td>\n",
       "      <td>svip-neuro-exam</td>\n",
       "      <td>5.45</td>\n",
       "      <td>5.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   SFARI_ID  BIDS_ID  site  age_years  latest_clinical_asd_dx  \\\n",
       "0             0   14702.x3  sub-001    60          8                   False   \n",
       "1             2  14705.x14  sub-003    50         34                   False   \n",
       "2             5  14714.x18  sub-006    60         21                   False   \n",
       "3             8  14723.x17  sub-009    60          5                   False   \n",
       "4            10  14725.x46  sub-011    50         10                   False   \n",
       "..          ...        ...      ...   ...        ...                     ...   \n",
       "129         201   15057.x1  sub-202    50         62                   False   \n",
       "130         202   15060.x1  sub-203    50         28                   False   \n",
       "131         204   15071.x1  sub-205    60         28                   False   \n",
       "132         206   15083.x5  sub-207    50         12                   False   \n",
       "133         207   15090.x1  sub-208    50         14                   False   \n",
       "\n",
       "    svip_diagnosis_m1           family_type genetic_status_16p ados_module  \\\n",
       "0     non-spectrum-dx          16p-deletion           deletion      ados-2   \n",
       "1        no-diagnosis       16p-duplication        duplication      ados-4   \n",
       "2        no-diagnosis          16p-deletion           deletion      ados-4   \n",
       "3     non-spectrum-dx       16p-duplication        duplication      ados-2   \n",
       "4        no-diagnosis       16p-duplication        duplication      ados-3   \n",
       "..                ...                   ...                ...         ...   \n",
       "129               NaN  non-familial-control                NaN         NaN   \n",
       "130               NaN  non-familial-control                NaN         NaN   \n",
       "131               NaN  non-familial-control                NaN         NaN   \n",
       "132   non-spectrum-dx          16p-deletion           deletion      ados-3   \n",
       "133               NaN  non-familial-control                NaN         NaN   \n",
       "\n",
       "     ...       measure_type     mother           relationship_to_iip  \\\n",
       "0    ...  diagnosis-summary   14702-x1  Initially identified proband   \n",
       "1    ...  diagnosis-summary   14705-x1                        Mother   \n",
       "2    ...  diagnosis-summary  14714-x12  Initially identified proband   \n",
       "3    ...  diagnosis-summary   14723-x9  Initially identified proband   \n",
       "4    ...  diagnosis-summary  14725-x55                        Cousin   \n",
       "..   ...                ...        ...                           ...   \n",
       "129  ...                NaN        NaN                           NaN   \n",
       "130  ...                NaN        NaN                           NaN   \n",
       "131  ...                NaN        NaN                           NaN   \n",
       "132  ...  diagnosis-summary   15083-x3  Initially identified proband   \n",
       "133  ...                NaN        NaN                           NaN   \n",
       "\n",
       "     svip_neuro_exam.background.head_circum  \\\n",
       "0                                      55.9   \n",
       "1                                       NaN   \n",
       "2                                      55.8   \n",
       "3                                       NaN   \n",
       "4                                      49.2   \n",
       "..                                      ...   \n",
       "129                                    58.0   \n",
       "130                                    60.0   \n",
       "131                                    57.5   \n",
       "132                                    58.0   \n",
       "133                                    52.5   \n",
       "\n",
       "     svip_neuro_exam.background.head_circum_perc  \\\n",
       "0                                            NaN   \n",
       "1                                            NaN   \n",
       "2                                            NaN   \n",
       "3                                            NaN   \n",
       "4                                            NaN   \n",
       "..                                           ...   \n",
       "129                                          NaN   \n",
       "130                                          NaN   \n",
       "131                                         95.0   \n",
       "132                                          NaN   \n",
       "133                                          NaN   \n",
       "\n",
       "     svip_neuro_exam.background.head_circum_z_score  \\\n",
       "0                                              2.18   \n",
       "1                                               NaN   \n",
       "2                                              0.49   \n",
       "3                                               NaN   \n",
       "4                                             -2.35   \n",
       "..                                              ...   \n",
       "129                                            2.02   \n",
       "130                                            3.42   \n",
       "131                                            1.67   \n",
       "132                                            2.77   \n",
       "133                                           -1.42   \n",
       "\n",
       "     svip_neuro_exam.measure.eval_age_months  \\\n",
       "0                                      119.0   \n",
       "1                                      405.0   \n",
       "2                                      249.0   \n",
       "3                                       60.0   \n",
       "4                                      120.0   \n",
       "..                                       ...   \n",
       "129                                    747.0   \n",
       "130                                    338.0   \n",
       "131                                    335.0   \n",
       "132                                    149.0   \n",
       "133                                    170.0   \n",
       "\n",
       "     svip_neuro_exam.measure.measure_type dur_run1 dur_run2  \n",
       "0                         svip-neuro-exam     5.00     4.25  \n",
       "1                         svip-neuro-exam     4.45     3.90  \n",
       "2                         svip-neuro-exam     6.00     6.00  \n",
       "3                         svip-neuro-exam     5.20     5.30  \n",
       "4                         svip-neuro-exam     4.30     2.00  \n",
       "..                                    ...      ...      ...  \n",
       "129                       svip-neuro-exam     4.45     4.70  \n",
       "130                       svip-neuro-exam     5.10     3.85  \n",
       "131                       svip-neuro-exam     6.00     5.70  \n",
       "132                       svip-neuro-exam     5.05     5.35  \n",
       "133                       svip-neuro-exam     5.45     5.40  \n",
       "\n",
       "[134 rows x 55 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/sfari_df_S134.csv')\n",
    "df\n",
    "\n",
    "# # Fix site id\n",
    "# unique_values = np.unique(df['site'].values)\n",
    "# new_vals = np.arange(1,len(unique_values)+1)\n",
    "# df['site'] = [new_vals[val==unique_values][0] for val in df['site'].values]\n",
    "\n",
    "# unique_values = np.unique(df['dataset'].values)\n",
    "# new_vals = np.arange(1,len(unique_values)+1)\n",
    "# df['dataset'] = [new_vals[val==unique_values][0] for val in df['dataset'].values]\n",
    "\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6aef62c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 51, 51)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmats = np.load('../Data/cmats_SFARI_S134.npy')\n",
    "cmats = ((cmats+1)/2)\n",
    "cmats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "562e69eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.556078357640601e-06, 1.0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cmats.min(),cmats.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1d357171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "class cvae_data_loader():\n",
    "    ''' this is the info'''\n",
    "    def __init__(self,cmats,df,batch_size=32):\n",
    "        \n",
    "        self.df = df\n",
    "        self.cmats = cmats\n",
    "        \n",
    "        self.n = len(df)\n",
    "        self.epoch = -1\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        \n",
    "        self.new_epoch()\n",
    "        self.n_batches = int(np.floor(min((len(self.asd_idxs),len(self.td_idxs)))/self.batch_size))\n",
    "        \n",
    "    def new_epoch(self):\n",
    "        \n",
    "        self.asd_idxs = np.nonzero((self.df['diag'].values==1))[0]\n",
    "        self.td_idxs = np.nonzero((self.df['diag'].values==2))[0]\n",
    "        \n",
    "        self.asd_idxs = np.random.permutation(self.asd_idxs)\n",
    "        self.td_idxs = np.random.permutation(self.td_idxs)\n",
    "        \n",
    "        self.epoch += 1\n",
    "        self.b = 0\n",
    "        \n",
    "        \n",
    "    def get_batch(self):\n",
    "        self.b += 1\n",
    "        \n",
    "        if self.b==self.n_batches:\n",
    "            self.new_epoch()\n",
    "        \n",
    "        self.batch_asd_idx = self.asd_idxs[np.arange(self.b*self.batch_size,self.b*self.batch_size+self.batch_size)]\n",
    "        self.batch_td_idx = self.td_idxs[np.arange(self.b*self.batch_size,self.b*self.batch_size+self.batch_size)]\n",
    "        \n",
    "        self.batch_asd = self.cmats[self.batch_asd_idx,:,:]\n",
    "        self.batch_td = self.cmats[self.batch_td_idx,:,:]\n",
    "        \n",
    "        self.batch_df = self.df.iloc[np.hstack((data_loader.batch_asd_idx,data_loader.batch_td_idx))]\n",
    "        \n",
    "        return self.batch_asd,self.batch_td,self.batch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5edab3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Test Data Loader\n",
    "# data_loader = cvae_data_loader(cmats=cmats, df=df, batch_size=32)\n",
    "# batch_asd,batch_td,batch_df = data_loader.get_batch()\n",
    "# batch_asd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8890333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_size = np.hstack((len(df),batch_asd.shape[1:]))\n",
    "# data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "003e3d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import mse\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_fMRI_CVAE_3D(input_shape=(51,51,1),\n",
    "                     latent_dim=[2,2],\n",
    "                     beta=1,\n",
    "                     disentangle=False,\n",
    "                     gamma=1,\n",
    "                     bias=True,\n",
    "                     batch_size = 32,\n",
    "                     kernel_size = 3,\n",
    "                     filters = 16,\n",
    "                     intermediate_dim = 128,\n",
    "                     nlayers = 2,\n",
    "                     strides = 2,\n",
    "                     learning_rate=0.001,\n",
    "                     opt=None):\n",
    "    \n",
    "    \n",
    "    ndim_bg = latent_dim[0]\n",
    "    ndim_sl = latent_dim[1]\n",
    "    \n",
    "    image_size, _, channels = input_shape\n",
    "\n",
    "    kernel_regularizer=regularizers.l2(.0001)\n",
    "\n",
    "    # build encoder model\n",
    "    tg_inputs = Input(shape=input_shape, name='tg_inputs')\n",
    "    bg_inputs = Input(shape=input_shape, name='bg_inputs')\n",
    "    \n",
    "    BatchNorm = tf.keras.layers.BatchNormalization(\n",
    "    axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True,\n",
    "    beta_initializer='zeros', gamma_initializer='ones',\n",
    "    moving_mean_initializer='zeros',\n",
    "    moving_variance_initializer='ones', beta_regularizer=None,\n",
    "    gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "\n",
    "    #kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0,stddev=5)\n",
    "    kernel_initializer = tf.keras.initializers.RandomUniform()\n",
    "\n",
    "    # generate latent vector Q(z|X)\n",
    "    \n",
    "    \n",
    "    z_h_layer = Dense(intermediate_dim,activation='relu', use_bias=bias,kernel_regularizer=kernel_regularizer)\n",
    "    z_mean_layer = Dense(ndim_bg, name='z_mean', use_bias=bias,kernel_regularizer=kernel_regularizer)\n",
    "    z_log_var_layer = Dense(ndim_bg, name='z_log_var', use_bias=bias,kernel_regularizer=kernel_regularizer)\n",
    "    z_layer = Lambda(sampling, output_shape=(ndim_bg,), name='z')\n",
    "\n",
    "    def z_encoder_func(inputs):\n",
    "        z_h = inputs\n",
    "\n",
    "        these_filters = filters\n",
    "        for i in range(nlayers):\n",
    "            these_filters *= 2\n",
    "            #print(these_filters)\n",
    "            z_h = Conv2D(filters=these_filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    activation='relu',\n",
    "                    strides=strides,\n",
    "                    padding='same',\n",
    "                    use_bias=bias,\n",
    "                    kernel_regularizer=kernel_regularizer)(z_h)\n",
    "        \n",
    "        # shape info needed to build decoder model\n",
    "        shape = K.int_shape(z_h)\n",
    "        z_h = Flatten()(z_h)\n",
    "        z_h = z_h_layer(z_h)\n",
    "        z_mean =  z_mean_layer(z_h)\n",
    "        #z_mean = BatchNorm(z_mean)\n",
    "        \n",
    "        z_log_var =  z_log_var_layer(z_h)\n",
    "        z = z_layer([z_mean, z_log_var])\n",
    "        return z_mean, z_log_var, z, shape\n",
    "\n",
    "    tg_z_mean, tg_z_log_var, tg_z, shape_z = z_encoder_func(tg_inputs)\n",
    "\n",
    "    # generate latent vector Q(z|X)\n",
    "    s_h_layer = Dense(intermediate_dim, activation='relu', use_bias=bias,kernel_regularizer=kernel_regularizer)\n",
    "    s_mean_layer = Dense(ndim_sl, name='s_mean', use_bias=bias,kernel_regularizer=kernel_regularizer)\n",
    "    s_log_var_layer = Dense(ndim_sl, name='s_log_var', use_bias=bias,kernel_regularizer=kernel_regularizer)\n",
    "    s_layer = Lambda(sampling, output_shape=(ndim_sl,), name='s')\n",
    "\n",
    "    def s_encoder_func(inputs):\n",
    "        s_h = inputs\n",
    "        these_filters = filters\n",
    "        for i in range(nlayers):\n",
    "            these_filters *= 2\n",
    "            s_h = Conv2D(filters=these_filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    activation='relu',\n",
    "                    strides=strides,\n",
    "                    use_bias=bias,\n",
    "                    kernel_regularizer=kernel_regularizer,\n",
    "                    padding='same')(s_h)\n",
    "        \n",
    "        # shape info needed to build decoder model\n",
    "        shape = K.int_shape(s_h)\n",
    "        s_h = Flatten()(s_h)\n",
    "        s_h = s_h_layer(s_h)\n",
    "        s_mean =  s_mean_layer(s_h)\n",
    "        #s_mean = BatchNorm(s_mean)\n",
    "        \n",
    "        s_log_var =  s_log_var_layer(s_h)        \n",
    "        s = s_layer([s_mean, s_log_var])\n",
    "        \n",
    "        return s_mean, s_log_var, s, shape\n",
    "\n",
    "    tg_s_mean, tg_s_log_var, tg_s, shape_s = s_encoder_func(tg_inputs)\n",
    "    bg_z_mean, bg_z_log_var, bg_z, _ = z_encoder_func(bg_inputs) # Aidas and Stefano team hax\n",
    "    \n",
    "    \n",
    "    # instantiate encoder models\n",
    "    z_encoder = tf.keras.models.Model(tg_inputs, [tg_z_mean, tg_z_log_var, tg_z], name='z_encoder')\n",
    "    s_encoder = tf.keras.models.Model(tg_inputs, [tg_s_mean, tg_s_log_var, tg_s], name='s_encoder')\n",
    "\n",
    "\n",
    "    # build decoder model\n",
    "    latent_inputs = Input(shape=(ndim_bg+ndim_sl,), name='z_sampling')\n",
    "\n",
    "    x = Dense(intermediate_dim, activation='relu', use_bias=bias,kernel_regularizer=kernel_regularizer,kernel_initializer=kernel_initializer)(latent_inputs)\n",
    "    x = Dense(shape_z[1] * shape_z[2] * shape_z[3], activation='relu', use_bias=bias,kernel_regularizer=kernel_regularizer,kernel_initializer=kernel_initializer)(x)\n",
    "    x = Reshape((shape_z[1], shape_z[2], shape_z[3]))(x)\n",
    "\n",
    "    these_filters = filters*(2**nlayers)/2\n",
    "    for i in range(nlayers-1):\n",
    "        x = Conv2DTranspose(filters=these_filters,\n",
    "                          kernel_size=kernel_size,\n",
    "                          activation='relu',\n",
    "                          strides=strides,\n",
    "                          use_bias=bias,\n",
    "                          kernel_regularizer=kernel_regularizer,\n",
    "                          padding='same')(x)\n",
    "        these_filters //= 2\n",
    "\n",
    "    outputs = Conv2DTranspose(filters=channels,\n",
    "                            kernel_size=kernel_size,\n",
    "                            activation='sigmoid',\n",
    "                            padding='same',\n",
    "                            strides=strides,\n",
    "                            use_bias=bias,\n",
    "                            kernel_regularizer=kernel_regularizer,\n",
    "                            name='decoder_output')(x)\n",
    "\n",
    "    # instantiate decoder model\n",
    "    cvae_decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "      # decoder.summary()\n",
    "\n",
    "    def zeros_like(x):\n",
    "        return tf.zeros_like(x)\n",
    "\n",
    "    tg_outputs = cvae_decoder(tf.keras.layers.concatenate([tg_z, tg_s], -1))\n",
    "    zeros = tf.keras.layers.Lambda(zeros_like)(tg_s)\n",
    "\n",
    "    bg_outputs = cvae_decoder(tf.keras.layers.concatenate([bg_z, zeros], -1)) # Aidas look into this, is this correct\n",
    "\n",
    "    cvae = tf.keras.models.Model(inputs=[tg_inputs, bg_inputs], \n",
    "                                  outputs=[tg_outputs, bg_outputs],\n",
    "                                  name='contrastive_vae')\n",
    "\n",
    "#     cvae_fg = tf.keras.models.Model(inputs=tg_inputs, \n",
    "#                                   outputs=fg_outputs, \n",
    "#                                   name='contrastive_vae_fg')\n",
    "\n",
    "    if disentangle:\n",
    "        discriminator = Dense(1, activation='sigmoid')\n",
    "\n",
    "        z1 = Lambda(lambda x: x[:int(batch_size/2),:])(tg_z)\n",
    "        z2 = Lambda(lambda x: x[int(batch_size/2):,:])(tg_z)\n",
    "        s1 = Lambda(lambda x: x[:int(batch_size/2),:])(tg_s)\n",
    "        s2 = Lambda(lambda x: x[int(batch_size/2):,:])(tg_s)\n",
    "\n",
    "        q_bar = tf.keras.layers.concatenate(\n",
    "          [tf.keras.layers.concatenate([s1, z2], axis=1),\n",
    "          tf.keras.layers.concatenate([s2, z1], axis=1)],\n",
    "          axis=0)\n",
    "\n",
    "        q = tf.keras.layers.concatenate(\n",
    "          [tf.keras.layers.concatenate([s1, z1], axis=1),\n",
    "          tf.keras.layers.concatenate([s2, z2], axis=1)],\n",
    "          axis=0)\n",
    "\n",
    "        q_bar_score = (discriminator(q_bar)+.1) *.85 # +.1 * .85 so that it's 0<x<1\n",
    "        q_score = (discriminator(q)+.1) *.85 \n",
    "        tc_loss = K.log(q_score / (1 - q_score)) \n",
    "        discriminator_loss = - K.log(q_score) - K.log(1 - q_bar_score)\n",
    "    else:\n",
    "        tc_loss = 0\n",
    "        discriminator_loss = 0\n",
    "\n",
    "\n",
    "    reconstruction_loss = tf.keras.losses.mse(K.flatten(tg_inputs), K.flatten(tg_outputs)) \n",
    "    reconstruction_loss += tf.keras.losses.mse(K.flatten(bg_inputs), K.flatten(bg_outputs)) \n",
    "    reconstruction_loss *= input_shape[0] * input_shape[1] * input_shape[2]\n",
    "\n",
    "    kl_loss1 = 1 + tg_z_log_var - tf.keras.backend.square(tg_z_mean) - tf.keras.backend.exp(tg_z_log_var)\n",
    "    kl_loss2 = 1 + tg_s_log_var - tf.keras.backend.square(tg_s_mean) - tf.keras.backend.exp(tg_s_log_var)\n",
    "    kl_loss3 = 1 + bg_z_log_var - tf.keras.backend.square(bg_z_mean) - tf.keras.backend.exp(bg_z_log_var)\n",
    "\n",
    "    kl_loss1 = tf.keras.backend.sum(kl_loss1, axis=-1)\n",
    "    kl_loss2 = tf.keras.backend.sum(kl_loss2, axis=-1)\n",
    "    kl_loss3 = tf.keras.backend.sum(kl_loss3, axis=-1)\n",
    "\n",
    "    kl_loss = kl_loss1+kl_loss2+kl_loss3\n",
    "    #kl_loss = tf.keras.backend.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    \n",
    "    cvae_loss = tf.keras.backend.mean(reconstruction_loss + beta*kl_loss + gamma*tc_loss + discriminator_loss)\n",
    "    cvae.add_loss(cvae_loss)\n",
    "    \n",
    "    if type(opt)==type(None):\n",
    "        #print('optimizer not specified using ADAM, wroom wroom')\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=learning_rate,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False,name='Adam')\n",
    "        #opt = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, momentum=0.9, epsilon=1e-07, centered=False, name='RMSprop')\n",
    "        #opt = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.1, nesterov=False, name='SGD')\n",
    "\n",
    "\n",
    "    cvae.compile(optimizer=opt,run_eagerly=True)\n",
    "    \n",
    "    return cvae, z_encoder, s_encoder, cvae_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "70561997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# params| 6,499,298\n"
     ]
    }
   ],
   "source": [
    "#import make_models;reload(make_models);from make_models import *\n",
    "batch_size = 32\n",
    "\n",
    "cvae, z_encoder, s_encoder, cvae_decoder = get_fMRI_CVAE_3D(input_shape=(64,64,1),\n",
    "                                                             latent_dim=[16,16],\n",
    "                                                             beta=.001,\n",
    "                                                             gamma=.001,\n",
    "                                                             disentangle=True,\n",
    "                                                             bias=True,\n",
    "                                                             batch_size = batch_size,\n",
    "                                                             kernel_size = 3,\n",
    "                                                             filters = 8,\n",
    "                                                             intermediate_dim = 128,\n",
    "                                                             nlayers = 6,\n",
    "                                                             strides = 2,\n",
    "                                                             learning_rate=0.001,\n",
    "                                                             opt=None)\n",
    "\n",
    "num_params = np.sum([np.prod(val.get_shape()) for val in cvae.trainable_weights])\n",
    "print(f'# params| {num_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "abb98f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x15527c1069d0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvae.load_weights(os.path.join(save_dir,'cvae_weights'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7c38bf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer zero_padding2d_7 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pad2d = tf.keras.layers.ZeroPadding2D(padding=((6,7),(6,7))) #If tuple of 2 tuples of 2 ints: interpreted as ((top_pad, bottom_pad), (left_pad, right_pad))\n",
    "#data_loader = cvae_data_loader(cmats=pad2d(cmats[:,:,:,np.newaxis])[:,:,:,0].numpy(), df=df, batch_size=batch_size)\n",
    "cmats = np.array(pad2d(cmats[:,:,:,np.newaxis])[:,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7e9b8e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvae_predict(z,s,asd):\n",
    "    \n",
    "    assert z.shape[0]==s.shape[0],'bad'\n",
    "    \n",
    "    if np.array(asd).ndim==0:\n",
    "        asd = np.repeat(asd,z.shape[0])\n",
    "        \n",
    "    z_ = np.zeros(s.shape)\n",
    "    s[~asd,:] = 0\n",
    "    \n",
    "    l = np.hstack((z,s))    \n",
    "    recon = cvae_decoder.predict(l)\n",
    "    \n",
    "    return recon[:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5e9deb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patients = df['diag'].values==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7dfec709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 458 ms, sys: 399 ms, total: 857 ms\n",
      "Wall time: 239 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Z_mu,Z_sigma,Z = z_encoder.predict(cmats)\n",
    "S_mu,S_sigma,S = s_encoder.predict(cmats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "738ee776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 25.48it/s]\n",
      "100%|██████████| 100/100 [00:03<00:00, 27.72it/s]\n"
     ]
    }
   ],
   "source": [
    "Z_sample100 = np.array([z_encoder.predict(cmats)[2] for _ in tqdm(range(100))])\n",
    "S_sample100 = np.array([s_encoder.predict(cmats)[2] for _ in tqdm(range(100))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fdc17edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_td_mu = cvae_predict(Z_mu,S_mu,asd=False)\n",
    "recon_asd_mu = cvae_predict(Z_mu,S_mu,asd=True)\n",
    "#recon_twin_mu = cvae_predict(Z_mu[patients,:],S_mu[patients,:],asd=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a359f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_td_mu = recon_td_mu[:,6:64-7,:][:,:,6:64-7]\n",
    "recon_asd_mu = recon_asd_mu[:,6:64-7,:][:,:,6:64-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "13d41de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recon_td_samples = np.array([cvae_predict(Z_sample100[i,~patients,:],S_sample100[i,~patients,:],asd=False) for i in tqdm(range(Z_sample100.shape[0]))])\n",
    "# recon_asd_samples = np.array([cvae_predict(Z_sample100[i,patients,:],S_sample100[i,patients,:],asd=True) for i in tqdm(range(Z_sample100.shape[0]))])\n",
    "# recon_twin_samples = np.array([cvae_predict(Z_sample100[i,patients,:],S_sample100[i,patients,:],asd=False) for i in tqdm(range(Z_sample100.shape[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "34c1ffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = dict()\n",
    "# results['Z_mu'] = Z_mu\n",
    "# results['Z_sigma'] = Z_sigma\n",
    "# results['Z'] = Z\n",
    "# results['S_mu'] = S_mu\n",
    "# results['S_sigma'] = S_sigma\n",
    "# results['S'] = S\n",
    "# results['Z_sample100'] = Z_sample100\n",
    "# results['S_sample100'] = S_sample100\n",
    "# results['recon_td_mu'] = recon_td_mu\n",
    "# results['recon_asd_mu'] = recon_asd_mu\n",
    "# results['recon_twin_mu'] = recon_twin_mu\n",
    "# results['recon_td_samples'] = recon_td_samples\n",
    "# results['recon_asd_samples'] = recon_asd_samples\n",
    "# results['recon_twin_samples'] = recon_twin_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "514c8a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the files\n",
    "# [np.savez_compressed(os.path.join(save_dir,key+'.npz'),data=results[key]) for key in tqdm(list(results.keys()))];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e33fd21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Dump as a pickle just in case\n",
    "# import pickle\n",
    "# with open((os.path.join(save_dir,'results.pickle')),'wb') as f:\n",
    "#     pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5e5b6b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../Assets/tf_weights/CVAE_2022-03-25 18:28:49.469238'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3721571a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 202 ms, sys: 1.13 ms, total: 203 ms\n",
      "Wall time: 207 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Save as a big numpy arr\n",
    "np.savez_compressed(file=os.path.join(save_dir,'sfari_latents.npz'),\n",
    "                    Z_mu=Z_mu,\n",
    "                    Z_sigma=Z_sigma,\n",
    "                    Z=Z,\n",
    "                    S_mu=S_mu,\n",
    "                    S_sigma=S_sigma,\n",
    "                    S=S,\n",
    "                    Z_sample100=Z_sample100,\n",
    "                    S_sample100=S_sample100,\n",
    "                    recon_td_mu=recon_td_mu,\n",
    "                    recon_asd_mu=recon_asd_mu)\n",
    "#                     recon_twin_mu=recon_twin_mu,\n",
    "#                     recon_td_samples=recon_td_samples,\n",
    "#                     recon_asd_samples=recon_asd_samples,\n",
    "#                     recon_twin_samples=recon_twin_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "27167fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# nb_name = '009-train-CVAE-cmats.ipynb'\n",
    "# shutil.copyfile(src=nb_name,dst=os.path.join(save_dir,nb_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b52fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "62a255b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 27 14:45:54 EDT 2022\n"
     ]
    }
   ],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f0ebbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb2b136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085d2b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625844da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
