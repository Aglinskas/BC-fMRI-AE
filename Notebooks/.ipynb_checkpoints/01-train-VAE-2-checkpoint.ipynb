{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mmfs1/data/aglinska/BC-fMRI-AE/Notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive namespace is empty.\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:            187           8         177           0           2         177\n",
      "Swap:            11           0          11\n"
     ]
    }
   ],
   "source": [
    "!free -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Sep 30 14:59:59 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.05    Driver Version: 450.51.05    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:18:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    43W / 300W |      3MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    41W / 300W |      3MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    63W / 300W |  12433MiB / 16160MiB |      7%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    41W / 300W |      3MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    2   N/A  N/A     21488      C   python3                          1439MiB |\n",
      "|    2   N/A  N/A     28190      C   python                          10991MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVAE_2021-09-30 15:00:00.089858\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime; now = datetime.now\n",
    "\n",
    "analysis_name = 'CVAE_'+str(now())\n",
    "save_dir = os.path.join('../Assets/tf_weights',analysis_name)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "    \n",
    "print(analysis_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory: 15.78173828125\n",
      "Free memory: 15.7783203125\n",
      "Used memory: 0.00341796875\n"
     ]
    }
   ],
   "source": [
    "# CHECK GPU\n",
    "import nvidia_smi\n",
    "try:\n",
    "    nvidia_smi.nvmlInit()\n",
    "\n",
    "    handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "    # card id 0 hardcoded here, there is also a call to get all available card ids, so we could iterate\n",
    "\n",
    "    info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "\n",
    "    print(\"Total memory:\", (info.total/1024/1024/1024))\n",
    "    print(\"Free memory:\", (info.free/1024/1024/1024))\n",
    "    print(\"Used memory:\", (info.used/1024/1024/1024))\n",
    "\n",
    "    nvidia_smi.nvmlShutdown()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "from umap import UMAP\n",
    "tqdm = partial(tqdm, position=0, leave=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/ABIDE_df2.csv')\n",
    "df = df.iloc[~pd.isna(df['bids_folder']).values]\n",
    "data_dir = '../Assets/fc_mats_32smooth_new/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sub-CMUa0050642.npy',\n",
       " 'sub-CMUa0050646.npy',\n",
       " 'sub-CMUa0050647.npy',\n",
       " 'sub-CMUa0050649.npy',\n",
       " 'sub-CMUa0050653.npy']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [file for file in os.listdir(data_dir) if file.endswith('.npy')]\n",
    "files.sort()\n",
    "files[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "subs_with_matFiles = [file.split('.')[0] for file in files]\n",
    "df = df.iloc[np.array([sub in subs_with_matFiles for sub in df['bids_folder'].values])]\n",
    "n_subs = len(df)\n",
    "print(n_subs)\n",
    "\n",
    "# Check if subject has .nii file\n",
    "has_file = np.array([os.path.exists(os.path.join(data_dir,sub + '.npy')) for sub in df['bids_folder'].values])\n",
    "print(has_file.mean())\n",
    "assert has_file.mean()==1.0, 'fuck'\n",
    "\n",
    "assert len(subs_with_matFiles)==len(df),'no'\n",
    "df = df.sort_values(by='bids_folder')\n",
    "assert all([subs_with_matFiles[i]==df['bids_folder'].values[i] for i in range(n_subs)]), 'out of order'\n",
    "\n",
    "df.index = np.arange(n_subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.2 ms, sys: 11.8 ms, total: 68 ms\n",
      "Wall time: 1.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow' from '/data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/__init__.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from importlib import reload\n",
    "import helper_funcs;reload(helper_funcs);from helper_funcs import *\n",
    "del helper_funcs\n",
    "import make_models;reload(make_models);from make_models import *\n",
    "del make_models\n",
    "\n",
    "from IPython import display\n",
    "import sys\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "reload(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../Assets/fc_mats_32smooth_new'\n",
    "data_loader = cvae_data_loader(data_dir=data_dir, df=df, batch_size=32)\n",
    "batch_asd,batch_td,batch_df = data_loader.get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = np.hstack((n_subs,batch_asd.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import make_models;reload(make_models);from make_models import *\n",
    "batch_size = 16\n",
    "\n",
    "cvae, z_encoder, s_encoder, cvae_decoder = get_fMRI_CVAE_4D(input_shape=tuple(data_size[1::]),\n",
    "                                                             latent_dim=32,\n",
    "                                                             beta=1,\n",
    "                                                             gamma=1,\n",
    "                                                             disentangle=True,\n",
    "                                                             bias=True,\n",
    "                                                             batch_size = batch_size,\n",
    "                                                             kernel_size = 3,\n",
    "                                                             filters = 16,\n",
    "                                                             intermediate_dim = 256,\n",
    "                                                             nlayers = 4,\n",
    "                                                             learning_rate=0.001,\n",
    "                                                             opt=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048, 32, 32, 32, 51)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = list()\n",
    "c_sim = list()\n",
    "all_rsas = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = cvae_data_loader(data_dir=data_dir, df=df, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "import make_models;reload(make_models);from make_models import *\n",
    "import helper_funcs;reload(helper_funcs);from helper_funcs import *\n",
    "\n",
    "for epoch in tqdm(range(100),position=0, leave=True):\n",
    "    for i in tqdm(range(data_loader.n_batches),position=1, leave=False):\n",
    "        \n",
    "        patient_batch,control_batch,batch_df = data_loader.get_batch() # Get a batch\n",
    "        hist = cvae.train_on_batch([patient_batch,control_batch]) # pass a batch\n",
    "        assert not np.isnan(hist),'loss is NaN - you f**cked up'  # check nothing crashed\n",
    "        loss.append(hist) # keep track of loss\n",
    "        \n",
    "        cvae.save_weights(os.path.join(save_dir,'cvae_weights')) # SAVE WEIGHTS\n",
    "        np.save(os.path.join(save_dir,'cvae_loss.npy'),np.array(loss)) # Save loss\n",
    "        \n",
    "        if np.mod(i,10)==0:\n",
    "            batch_rsas = get_batch_rsas(data_dir,df,z_encoder,s_encoder,batch_size=(df['DX_GROUP'].values==1).sum())\n",
    "        \n",
    "        c_sim,all_rsas = cvae_dashboard(data_loader.epoch,\n",
    "                                        data_loader.b,\n",
    "                                        i,\n",
    "                                        cvae,z_encoder,\n",
    "                                        s_encoder,\n",
    "                                        loss,\n",
    "                                        all_rsas,\n",
    "                                        c_sim,\n",
    "                                        df,\n",
    "                                        patient_batch,\n",
    "                                        control_batch,\n",
    "                                        batch_rsas,\n",
    "                                        red='UMAP') # plot training progress\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
