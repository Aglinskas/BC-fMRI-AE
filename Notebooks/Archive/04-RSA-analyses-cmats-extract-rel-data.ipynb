{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52e0d9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mmfs1/data/aglinska/BC-fMRI-AE/Notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51063078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f84dfc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>DX_GROUP</th>\n",
       "      <th>DSM_IV_TR</th>\n",
       "      <th>AGE_AT_SCAN</th>\n",
       "      <th>SEX</th>\n",
       "      <th>HANDEDNESS_CATEGORY</th>\n",
       "      <th>HANDEDNESS_SCORES</th>\n",
       "      <th>FIQ</th>\n",
       "      <th>VIQ</th>\n",
       "      <th>PIQ</th>\n",
       "      <th>...</th>\n",
       "      <th>WISC_IV_MATRIX_SCALED</th>\n",
       "      <th>WISC_IV_DIGIT_SPAN_SCALED</th>\n",
       "      <th>WISC_IV_LET_NUM_SCALED</th>\n",
       "      <th>WISC_IV_CODING_SCALED</th>\n",
       "      <th>WISC_IV_SYM_SCALED</th>\n",
       "      <th>EYE_STATUS_AT_SCAN</th>\n",
       "      <th>AGE_AT_MPRAGE</th>\n",
       "      <th>BMI</th>\n",
       "      <th>bids_folder</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>50642</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sub-CMUa0050642</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>50646</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sub-CMUa0050646</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>50647</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sub-CMUa0050647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     participant_id  DX_GROUP  DSM_IV_TR  AGE_AT_SCAN  SEX  \\\n",
       "460           50642         1        1.0         33.0    1   \n",
       "464           50646         1        1.0         21.0    1   \n",
       "465           50647         1        1.0         27.0    1   \n",
       "\n",
       "    HANDEDNESS_CATEGORY  HANDEDNESS_SCORES    FIQ    VIQ    PIQ  ...  \\\n",
       "460                   R                NaN  103.0   98.0  107.0  ...   \n",
       "464                   R                NaN  108.0  100.0  115.0  ...   \n",
       "465                   R                NaN  104.0   97.0  109.0  ...   \n",
       "\n",
       "    WISC_IV_MATRIX_SCALED WISC_IV_DIGIT_SPAN_SCALED WISC_IV_LET_NUM_SCALED  \\\n",
       "460                   NaN                       NaN                    NaN   \n",
       "464                   NaN                       NaN                    NaN   \n",
       "465                   NaN                       NaN                    NaN   \n",
       "\n",
       "     WISC_IV_CODING_SCALED  WISC_IV_SYM_SCALED  EYE_STATUS_AT_SCAN  \\\n",
       "460                    NaN                 NaN                   2   \n",
       "464                    NaN                 NaN                   2   \n",
       "465                    NaN                 NaN                   2   \n",
       "\n",
       "     AGE_AT_MPRAGE  BMI      bids_folder  site  \n",
       "460            NaN  NaN  sub-CMUa0050642     1  \n",
       "464            NaN  NaN  sub-CMUa0050646     1  \n",
       "465            NaN  NaN  sub-CMUa0050647     1  \n",
       "\n",
       "[3 rows x 75 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/ABIDE_df2.csv')\n",
    "df = df.iloc[~pd.isna(df['bids_folder']).values]\n",
    "df = df.sort_values(by='bids_folder')\n",
    "print(len(df))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1f631b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = '../Assets/abide_1_cmats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "486ad7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cData = np.array([np.load(os.path.join(data_dir,sub+'.npy')) for sub in df['bids_folder'].values])\n",
    "\n",
    "# print(f'Original data range: {(cData.min(),cData.max())}')\n",
    "# cData = (cData+1)/2\n",
    "# print(f'Normalized data range: {(cData.min(),cData.max())}')\n",
    "# cData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "550373e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import ZeroPadding2D\n",
    "pad2d = ZeroPadding2D(padding=((6,7),(6,7))) #If tuple of 2 tuples of 2 ints: interpreted as ((top_pad, bottom_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b48e79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cData_pad = pad2d(cData[:,:,:,np.newaxis])\n",
    "# cData_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5b2d7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(cData_pad[0,:,:,0]);plt.xticks([]);plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc39f66",
   "metadata": {},
   "source": [
    "## DEFINE MODEL AND LOAD WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fd69340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import mse\n",
    "from tensorflow.keras import regularizers\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "    # Arguments:\n",
    "      args (tensor): mean and log of variance of Q(z|X)\n",
    "    # Returns:\n",
    "      z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "def get_fMRI_CVAE_3D(input_shape=(51,51,1),\n",
    "                     latent_dim=[2,2],\n",
    "                     beta=1,\n",
    "                     disentangle=False,\n",
    "                     gamma=1,\n",
    "                     bias=True,\n",
    "                     batch_size = 32,\n",
    "                     kernel_size = 3,\n",
    "                     filters = 16,\n",
    "                     intermediate_dim = 128,\n",
    "                     nlayers = 2,\n",
    "                     learning_rate=0.001,\n",
    "                     opt=None):\n",
    "    \n",
    "    \n",
    "    ndim_bg = latent_dim[0]\n",
    "    ndim_sl = latent_dim[1]\n",
    "    \n",
    "    image_size, _, channels = input_shape\n",
    "\n",
    "    kernel_regularizer=regularizers.l2(.0001)\n",
    "\n",
    "    # build encoder model\n",
    "    tg_inputs = Input(shape=input_shape, name='tg_inputs')\n",
    "    bg_inputs = Input(shape=input_shape, name='bg_inputs')\n",
    "    \n",
    "    BatchNorm = tf.keras.layers.BatchNormalization(\n",
    "    axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True,\n",
    "    beta_initializer='zeros', gamma_initializer='ones',\n",
    "    moving_mean_initializer='zeros',\n",
    "    moving_variance_initializer='ones', beta_regularizer=None,\n",
    "    gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "\n",
    "    #kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0,stddev=5)\n",
    "    kernel_initializer = tf.keras.initializers.RandomUniform()\n",
    "\n",
    "    # generate latent vector Q(z|X)\n",
    "    \n",
    "    \n",
    "    z_h_layer = Dense(intermediate_dim,activation='relu', use_bias=bias,kernel_regularizer=kernel_regularizer)\n",
    "    z_mean_layer = Dense(ndim_bg, name='z_mean', use_bias=bias,kernel_regularizer=kernel_regularizer)\n",
    "    z_log_var_layer = Dense(ndim_bg, name='z_log_var', use_bias=bias,kernel_regularizer=kernel_regularizer)\n",
    "    z_layer = Lambda(sampling, output_shape=(ndim_bg,), name='z')\n",
    "\n",
    "    def z_encoder_func(inputs):\n",
    "        z_h = inputs\n",
    "\n",
    "        these_filters = filters\n",
    "        for i in range(nlayers):\n",
    "            these_filters *= 2\n",
    "            #print(these_filters)\n",
    "            z_h = Conv2D(filters=these_filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    activation='relu',\n",
    "                    strides=2,\n",
    "                    padding='same',\n",
    "                    use_bias=bias,\n",
    "                    kernel_regularizer=kernel_regularizer)(z_h)\n",
    "        \n",
    "        # shape info needed to build decoder model\n",
    "        shape = K.int_shape(z_h)\n",
    "        z_h = Flatten()(z_h)\n",
    "        z_h = z_h_layer(z_h)\n",
    "        z_mean =  z_mean_layer(z_h)\n",
    "        #z_mean = BatchNorm(z_mean)\n",
    "        \n",
    "        z_log_var =  z_log_var_layer(z_h)\n",
    "        z = z_layer([z_mean, z_log_var])\n",
    "        return z_mean, z_log_var, z, shape\n",
    "\n",
    "    tg_z_mean, tg_z_log_var, tg_z, shape_z = z_encoder_func(tg_inputs)\n",
    "\n",
    "    # generate latent vector Q(z|X)\n",
    "    s_h_layer = Dense(intermediate_dim, activation='relu', use_bias=bias,kernel_regularizer=kernel_regularizer)\n",
    "    s_mean_layer = Dense(ndim_sl, name='s_mean', use_bias=bias,kernel_regularizer=kernel_regularizer)\n",
    "    s_log_var_layer = Dense(ndim_sl, name='s_log_var', use_bias=bias,kernel_regularizer=kernel_regularizer)\n",
    "    s_layer = Lambda(sampling, output_shape=(ndim_sl,), name='s')\n",
    "\n",
    "    def s_encoder_func(inputs):\n",
    "        s_h = inputs\n",
    "        these_filters = filters\n",
    "        for i in range(nlayers):\n",
    "            these_filters *= 2\n",
    "            s_h = Conv2D(filters=these_filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    activation='relu',\n",
    "                    strides=2,\n",
    "                    use_bias=bias,\n",
    "                    kernel_regularizer=kernel_regularizer,\n",
    "                    padding='same')(s_h)\n",
    "        \n",
    "        # shape info needed to build decoder model\n",
    "        shape = K.int_shape(s_h)\n",
    "        s_h = Flatten()(s_h)\n",
    "        s_h = s_h_layer(s_h)\n",
    "        s_mean =  s_mean_layer(s_h)\n",
    "        #s_mean = BatchNorm(s_mean)\n",
    "        \n",
    "        s_log_var =  s_log_var_layer(s_h)        \n",
    "        s = s_layer([s_mean, s_log_var])\n",
    "        \n",
    "        return s_mean, s_log_var, s, shape\n",
    "\n",
    "    tg_s_mean, tg_s_log_var, tg_s, shape_s = s_encoder_func(tg_inputs)\n",
    "    bg_z_mean, bg_z_log_var, bg_z, _ = z_encoder_func(bg_inputs) # Aidas and Stefano team hax\n",
    "    \n",
    "    \n",
    "    # instantiate encoder models\n",
    "    z_encoder = tf.keras.models.Model(tg_inputs, [tg_z_mean, tg_z_log_var, tg_z], name='z_encoder')\n",
    "    s_encoder = tf.keras.models.Model(tg_inputs, [tg_s_mean, tg_s_log_var, tg_s], name='s_encoder')\n",
    "\n",
    "\n",
    "    # build decoder model\n",
    "    latent_inputs = Input(shape=(ndim_bg+ndim_sl,), name='z_sampling')\n",
    "\n",
    "    x = Dense(intermediate_dim, activation='relu', use_bias=bias,kernel_regularizer=kernel_regularizer,kernel_initializer=kernel_initializer)(latent_inputs)\n",
    "    x = Dense(shape_z[1] * shape_z[2] * shape_z[3], activation='relu', use_bias=bias,kernel_regularizer=kernel_regularizer,kernel_initializer=kernel_initializer)(x)\n",
    "    x = Reshape((shape_z[1], shape_z[2], shape_z[3]))(x)\n",
    "\n",
    "    these_filters = filters*(2**nlayers)/2\n",
    "    for i in range(nlayers-1):\n",
    "        x = Conv2DTranspose(filters=these_filters,\n",
    "                          kernel_size=kernel_size,\n",
    "                          activation='relu',\n",
    "                          strides=2,\n",
    "                          use_bias=bias,\n",
    "                          kernel_regularizer=kernel_regularizer,\n",
    "                          padding='same')(x)\n",
    "        these_filters //= 2\n",
    "\n",
    "    outputs = Conv2DTranspose(filters=channels,\n",
    "                            kernel_size=kernel_size,\n",
    "                            activation='sigmoid',\n",
    "                            padding='same',\n",
    "                            strides=2,\n",
    "                            use_bias=bias,\n",
    "                            kernel_regularizer=kernel_regularizer,\n",
    "                            name='decoder_output')(x)\n",
    "\n",
    "    # instantiate decoder model\n",
    "    cvae_decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "      # decoder.summary()\n",
    "\n",
    "    def zeros_like(x):\n",
    "        return tf.zeros_like(x)\n",
    "\n",
    "    tg_outputs = cvae_decoder(tf.keras.layers.concatenate([tg_z, tg_s], -1))\n",
    "    zeros = tf.keras.layers.Lambda(zeros_like)(tg_s)\n",
    "\n",
    "    bg_outputs = cvae_decoder(tf.keras.layers.concatenate([bg_z, zeros], -1)) # Aidas look into this, is this correct\n",
    "\n",
    "    cvae = tf.keras.models.Model(inputs=[tg_inputs, bg_inputs], \n",
    "                                  outputs=[tg_outputs, bg_outputs],\n",
    "                                  name='contrastive_vae')\n",
    "\n",
    "#     cvae_fg = tf.keras.models.Model(inputs=tg_inputs, \n",
    "#                                   outputs=fg_outputs, \n",
    "#                                   name='contrastive_vae_fg')\n",
    "\n",
    "    if disentangle:\n",
    "        discriminator = Dense(1, activation='sigmoid')\n",
    "\n",
    "        z1 = Lambda(lambda x: x[:int(batch_size/2),:])(tg_z)\n",
    "        z2 = Lambda(lambda x: x[int(batch_size/2):,:])(tg_z)\n",
    "        s1 = Lambda(lambda x: x[:int(batch_size/2),:])(tg_s)\n",
    "        s2 = Lambda(lambda x: x[int(batch_size/2):,:])(tg_s)\n",
    "\n",
    "        q_bar = tf.keras.layers.concatenate(\n",
    "          [tf.keras.layers.concatenate([s1, z2], axis=1),\n",
    "          tf.keras.layers.concatenate([s2, z1], axis=1)],\n",
    "          axis=0)\n",
    "\n",
    "        q = tf.keras.layers.concatenate(\n",
    "          [tf.keras.layers.concatenate([s1, z1], axis=1),\n",
    "          tf.keras.layers.concatenate([s2, z2], axis=1)],\n",
    "          axis=0)\n",
    "\n",
    "        q_bar_score = (discriminator(q_bar)+.1) *.85 # +.1 * .85 so that it's 0<x<1\n",
    "        q_score = (discriminator(q)+.1) *.85 \n",
    "        tc_loss = K.log(q_score / (1 - q_score)) \n",
    "        discriminator_loss = - K.log(q_score) - K.log(1 - q_bar_score)\n",
    "    else:\n",
    "        tc_loss = 0\n",
    "        discriminator_loss = 0\n",
    "\n",
    "\n",
    "    reconstruction_loss = tf.keras.losses.mse(K.flatten(tg_inputs[:,6:57,6:57,:]), K.flatten(tg_outputs[:,6:57,6:57,:])) \n",
    "    reconstruction_loss += tf.keras.losses.mse(K.flatten(bg_inputs[:,6:57,6:57,:]), K.flatten(bg_outputs[:,6:57,6:57,:])) \n",
    "    reconstruction_loss *= input_shape[0] * input_shape[1] * input_shape[2]\n",
    "\n",
    "    kl_loss1 = 1 + tg_z_log_var - tf.keras.backend.square(tg_z_mean) - tf.keras.backend.exp(tg_z_log_var)\n",
    "    kl_loss2 = 1 + tg_s_log_var - tf.keras.backend.square(tg_s_mean) - tf.keras.backend.exp(tg_s_log_var)\n",
    "    kl_loss3 = 1 + bg_z_log_var - tf.keras.backend.square(bg_z_mean) - tf.keras.backend.exp(bg_z_log_var)\n",
    "\n",
    "    kl_loss1 = tf.keras.backend.sum(kl_loss1, axis=-1)\n",
    "    kl_loss2 = tf.keras.backend.sum(kl_loss2, axis=-1)\n",
    "    kl_loss3 = tf.keras.backend.sum(kl_loss3, axis=-1)\n",
    "\n",
    "    kl_loss = kl_loss1+kl_loss2+kl_loss3\n",
    "    #kl_loss = tf.keras.backend.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    \n",
    "    cvae_loss = tf.keras.backend.mean(reconstruction_loss + beta*kl_loss + gamma*tc_loss + discriminator_loss)\n",
    "    cvae.add_loss(cvae_loss)\n",
    "    \n",
    "    if type(opt)==type(None):\n",
    "        #print('optimizer not specified using ADAM, wroom wroom')\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=learning_rate,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False,name='Adam')\n",
    "        #opt = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, momentum=0.9, epsilon=1e-07, centered=False, name='RMSprop')\n",
    "        #opt = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.1, nesterov=False, name='SGD')\n",
    "\n",
    "\n",
    "    cvae.compile(optimizer=opt,run_eagerly=True)\n",
    "    \n",
    "    return cvae, z_encoder, s_encoder, cvae_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0df7691a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# params| 1,189,730\n"
     ]
    }
   ],
   "source": [
    "#import make_models;reload(make_models);from make_models import *\n",
    "\n",
    "batch_size = 32\n",
    "cvae, z_encoder, s_encoder, cvae_decoder = get_fMRI_CVAE_3D(input_shape=(64,64,1),\n",
    "                                                             latent_dim=[16,16],\n",
    "                                                             beta=.001,\n",
    "                                                             gamma=1,\n",
    "                                                             disentangle=True,\n",
    "                                                             bias=True,\n",
    "                                                             batch_size = batch_size,\n",
    "                                                             kernel_size = 3,\n",
    "                                                             filters = 8,\n",
    "                                                             intermediate_dim = 128,\n",
    "                                                             nlayers = 4,\n",
    "                                                             learning_rate=0.001,\n",
    "                                                             opt=None)\n",
    "\n",
    "num_params = np.sum([np.prod(val.get_shape()) for val in cvae.trainable_weights])\n",
    "print(f'# params| {num_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fb068b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dir = '../Assets/tf_weights/'\n",
    "analysis_name = 'CVAE_2021-10-27 11:41:44.052073'\n",
    "#analysis_name = 'CVAE_2021-10-28 05:12:17.623449'\n",
    "weights_fn = os.path.join(weights_dir,analysis_name,'cvae_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "984bb321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x155167a1dcd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvae.load_weights(weights_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5440430",
   "metadata": {},
   "source": [
    "## GET DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40ed4b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arr', 'subs']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('../Data/rel-cmats.npz',allow_pickle=True)\n",
    "list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a1929bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1086, 51, 51, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmats = data['arr']\n",
    "subs = data['subs']\n",
    "\n",
    "isnan = np.array([np.isnan(cmats[i,:,:,:]).sum()==0 for i in range(cmats.shape[0])])\n",
    "cmats = cmats[isnan,:,:,:]\n",
    "subs = subs[isnan]\n",
    "cmats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "636c6eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsubs = cmats.shape[0]\n",
    "svec = np.arange(nsubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d09056c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z1_mu,Z1_var,Z1 = z_encoder.predict(pad2d(cmats[:,:,:,0][:,:,:,np.newaxis]))\n",
    "Z2_mu,Z2_var,Z2 = z_encoder.predict(pad2d(cmats[:,:,:,1][:,:,:,np.newaxis]))\n",
    "\n",
    "S1_mu,S1_var,S1 = z_encoder.predict(pad2d(cmats[:,:,:,0][:,:,:,np.newaxis]))\n",
    "S2_mu,S2_var,S2 = z_encoder.predict(pad2d(cmats[:,:,:,1][:,:,:,np.newaxis]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "fcc00cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRanks(first_half,second_half):\n",
    "    import scipy\n",
    "    from tqdm import tqdm\n",
    "    corr = scipy.stats.spearmanr\n",
    "    dist = lambda v1,v2 : corr(v1,v2)[0]\n",
    "    #dist = lambda v1,v2 : scipy.spatial.distance.pdist(np.array([v1,v2]))[0]\n",
    "\n",
    "    s = 0\n",
    "    ranks = list()\n",
    "    for s in tqdm(range(nsubs)):\n",
    "        within = dist(first_half[s,:],second_half[s,:])\n",
    "        other_subs = svec[svec!=s]\n",
    "        across = np.array([dist(first_half[s,:],second_half[ss,:]) for ss in other_subs])\n",
    "        rank = (within < across).sum()+1\n",
    "        #rank = (within > across).sum()+1\n",
    "        ranks.append(rank)\n",
    "\n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "45e0878e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1046,)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_subs = np.intersect1d(df['bids_folder'].values,subs)\n",
    "df = df.iloc[np.array([val in common_subs for val in df['bids_folder'].values])]\n",
    "common_subs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "180bf5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1086/1086 [07:37<00:00,  2.37it/s]\n"
     ]
    }
   ],
   "source": [
    "Z_ranks = getRanks(Z1,Z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "3fec1538",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1086/1086 [07:37<00:00,  2.37it/s]\n"
     ]
    }
   ],
   "source": [
    "S_ranks = getRanks(S1,S2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "2294003c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1086/1086 [11:08<00:00,  1.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from helper_funcs import get_triu\n",
    "C1 = np.array([get_triu(cmats[i,:,:,0]) for i in range(nsubs)])\n",
    "C2 = np.array([get_triu(cmats[i,:,:,1]) for i in range(nsubs)])\n",
    "C_ranks = getRanks(C1,C2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "b190b2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1086,)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_ranks = np.array(C_ranks)\n",
    "Z_ranks = np.array(Z_ranks)\n",
    "S_ranks = np.array(S_ranks)\n",
    "S_ranks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "246e15d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = np.array([sub in common_subs for sub in subs])\n",
    "C_rankz = C_ranks[vv]\n",
    "Z_rankz = Z_ranks[vv]\n",
    "S_rankz = S_ranks[vv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "2298c910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1046,)\n",
      "(1086,)\n",
      "(1086,)\n"
     ]
    }
   ],
   "source": [
    "print(C_rankz.shape)\n",
    "print(Z_ranks.shape)\n",
    "print(S_ranks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "e8eacaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.14531548757171\n",
      "3.1307550644567224\n",
      "3.2228360957642725\n"
     ]
    }
   ],
   "source": [
    "print((C_rankz==1).mean()*100)\n",
    "print((Z_ranks==1).mean()*100)\n",
    "print((S_ranks==1).mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "c4ef2cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(C_rankz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "dc8787e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107.5"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(Z_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "989f05a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104.5"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(S_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "7cb9aba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = df['DX_GROUP'].values==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "08404b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904296875"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(C_rankz[patients]==1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "0f9b1258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03125"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Z_ranks[patients]==1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e5179c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03515625"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(S_ranks[patients]==1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2fd4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a97876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5981c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd62b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dac58d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2eb0e40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patients = df['DX_GROUP'].values==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aad7f228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_data = cData_pad\n",
    "\n",
    "# Z_mu,Z_sigma,Z = z_encoder.predict(use_data)\n",
    "# S_mu,S_sigma,S = s_encoder.predict(use_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "658d01ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da97f416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_samples = np.array([z_encoder.predict(use_data)[2] for i in tqdm(range(100))])\n",
    "# s_samples = np.array([s_encoder.predict(use_data)[2] for i in tqdm(range(100))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8194209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "42a2b35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import umap\n",
    "# reducer = umap.UMAP(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "54d595cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_embedding = reducer.fit_transform(S[patients,:])\n",
    "# z_embedding = reducer.fit_transform(Z[patients,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c7c8b54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,5))\n",
    "# plt.subplot(1,2,2);plt.scatter(z_embedding[:,0],z_embedding[:,1])\n",
    "# plt.subplot(1,2,1);plt.scatter(s_embedding[:,0],s_embedding[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4e635b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_cmat(s,is_asd,idx=None):\n",
    "#     # s = 0\n",
    "#     # idx=None\n",
    "#     # is_asd = patients[s]\n",
    "#     # is_asd = False\n",
    "\n",
    "#     if type(idx)==type(None):\n",
    "#         bg_vec = Z[s,:]\n",
    "#         sl_vec = S[s,:]\n",
    "#     else:\n",
    "#         bg_vec = z_samples[idx,s,:]\n",
    "#         sl_vec = s_samples[idx,s,:]\n",
    "\n",
    "#     zeroes_ = np.zeros(sl_vec.shape)\n",
    "\n",
    "#     if is_asd:\n",
    "#         vec = np.hstack((bg_vec,sl_vec))\n",
    "#     else:\n",
    "#         vec = np.hstack((bg_vec,zeroes_))\n",
    "\n",
    "#     predicted = cvae_decoder.predict(vec[np.newaxis,:])[0,:,:,0]\n",
    "#     predicted_depad = predicted[6:57,6:57]\n",
    "    \n",
    "#     return predicted_depad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4eb7df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted = np.array([predict_cmat(s,patients[s],idx=None) for s in tqdm(range(len(df)))])\n",
    "# predicted_bg = np.array([predict_cmat(s,False,idx=None) for s in tqdm(range(len(df)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121d10d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "159d3211",
   "metadata": {},
   "source": [
    "### Variability of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "01f89152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc = np.array([predict_cmat(s=0,is_asd=patients[0],idx=i) for i in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3284d1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = np.array([get_triu(cc[i,:,:]) for i in range(100)]).std(axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3aba7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# plt.figure(figsize=(10,10))\n",
    "# print(cc.std(axis=0).max())\n",
    "# print(cc.std(axis=0).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8467885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap(((cc[0,:,:]-cc[1,:,:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "85600c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helper_funcs import get_triu\n",
    "# #abs(get_triu((cc[50,:,:]-cc[10,:,:]))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "963edc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ccc = np.array([get_triu(predicted[i,:,:]) for i in range(predicted.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c27107b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio = ccc.std(axis=0).mean() / c\n",
    "# f'between sub variability is {ratio:.2f} times larger than within sub variability'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "95a71392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_samples = np.zeros((100,len(df),51,51))\n",
    "# predicted_bg_samples = np.zeros((100,len(df),51,51))\n",
    "# for s in  tqdm(range(len(df))):\n",
    "#     for idx in range(100):\n",
    "#         predicted_samples[idx,s,:,:] = predict_cmat(s,patients[s],idx=idx)\n",
    "#         predicted_bg_samples[idx,s,:,:] = predict_cmat(s,False,idx=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9937aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent_data = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7b93726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent_data['cData'] = cData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "667eb132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent_data['Z_mu'] = Z_mu\n",
    "# latent_data['Z_sigma'] = Z_sigma\n",
    "# latent_data['Z'] = Z\n",
    "\n",
    "# latent_data['S_mu'] = S_mu\n",
    "# latent_data['S_sigma'] = S_sigma\n",
    "# latent_data['S'] = S\n",
    "\n",
    "# latent_data['z_samples'] = z_samples\n",
    "# latent_data['s_samples'] = s_samples\n",
    "\n",
    "# latent_data['z_embedding'] = z_embedding\n",
    "# latent_data['s_embedding'] = s_embedding\n",
    "\n",
    "# latent_data['predicted'] = predicted\n",
    "# latent_data['predicted_bg'] = predicted_bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdcb7067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CVAE_2021-10-28 05:12:17.623449'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analysis_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be053ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../Data/cmat_latents_CVAE_2021-10-28 05:12:17.623449.pickle'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ofn = os.path.join('../Data',f'cmat_latents_{analysis_name}.pickle')\n",
    "# ofn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "182c13fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump(obj=latent_data,file=open(ofn,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69142cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
