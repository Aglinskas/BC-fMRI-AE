{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mmfs1/data/aglinska/BC-fMRI-AE/Notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:            187           3         180           1           3         181\n",
      "Swap:            11           0          11\n"
     ]
    }
   ],
   "source": [
    "!free -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  7 05:53:45 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.05    Driver Version: 450.51.05    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:18:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    70W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    41W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    43W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    40W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVAE_2021-12-07 05:53:45.305343\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime; now = datetime.now\n",
    "\n",
    "analysis_name = 'CVAE_'+str(now())\n",
    "save_dir = os.path.join('../Assets/tf_weights',analysis_name)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "    \n",
    "print(analysis_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory: 15.78173828125\n",
      "Free memory: 15.7816162109375\n",
      "Used memory: 0.0001220703125\n"
     ]
    }
   ],
   "source": [
    "# CHECK GPU\n",
    "import nvidia_smi\n",
    "try:\n",
    "    nvidia_smi.nvmlInit()\n",
    "\n",
    "    handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "    # card id 0 hardcoded here, there is also a call to get all available card ids, so we could iterate\n",
    "\n",
    "    info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "\n",
    "    print(\"Total memory:\", (info.total/1024/1024/1024))\n",
    "    print(\"Free memory:\", (info.free/1024/1024/1024))\n",
    "    print(\"Used memory:\", (info.used/1024/1024/1024))\n",
    "\n",
    "    nvidia_smi.nvmlShutdown()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "from umap import UMAP\n",
    "tqdm = partial(tqdm, position=0, leave=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mmfs1/data/aglinska/BC-fMRI-AE/Notebooks'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>DX_GROUP</th>\n",
       "      <th>DSM_IV_TR</th>\n",
       "      <th>AGE_AT_SCAN</th>\n",
       "      <th>SEX</th>\n",
       "      <th>HANDEDNESS_CATEGORY</th>\n",
       "      <th>HANDEDNESS_SCORES</th>\n",
       "      <th>FIQ</th>\n",
       "      <th>VIQ</th>\n",
       "      <th>...</th>\n",
       "      <th>WISC_IV_DIGIT_SPAN_SCALED</th>\n",
       "      <th>WISC_IV_LET_NUM_SCALED</th>\n",
       "      <th>WISC_IV_CODING_SCALED</th>\n",
       "      <th>WISC_IV_SYM_SCALED</th>\n",
       "      <th>EYE_STATUS_AT_SCAN</th>\n",
       "      <th>AGE_AT_MPRAGE</th>\n",
       "      <th>BMI</th>\n",
       "      <th>bids_folder</th>\n",
       "      <th>site</th>\n",
       "      <th>funcFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>460</td>\n",
       "      <td>50642</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sub-CMUa0050642</td>\n",
       "      <td>1</td>\n",
       "      <td>CMU_a_0050642_func_preproc.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>464</td>\n",
       "      <td>50646</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sub-CMUa0050646</td>\n",
       "      <td>1</td>\n",
       "      <td>CMU_a_0050646_func_preproc.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>465</td>\n",
       "      <td>50647</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sub-CMUa0050647</td>\n",
       "      <td>1</td>\n",
       "      <td>CMU_a_0050647_func_preproc.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>467</td>\n",
       "      <td>50649</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sub-CMUa0050649</td>\n",
       "      <td>1</td>\n",
       "      <td>CMU_a_0050649_func_preproc.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>471</td>\n",
       "      <td>50653</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>134.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sub-CMUa0050653</td>\n",
       "      <td>1</td>\n",
       "      <td>CMU_a_0050653_func_preproc.nii.gz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  participant_id  DX_GROUP  DSM_IV_TR  AGE_AT_SCAN  SEX  \\\n",
       "460         460           50642         1        1.0         33.0    1   \n",
       "464         464           50646         1        1.0         21.0    1   \n",
       "465         465           50647         1        1.0         27.0    1   \n",
       "467         467           50649         1        1.0         22.0    1   \n",
       "471         471           50653         1        1.0         30.0    1   \n",
       "\n",
       "    HANDEDNESS_CATEGORY  HANDEDNESS_SCORES    FIQ    VIQ  ...  \\\n",
       "460                   R                NaN  103.0   98.0  ...   \n",
       "464                   R                NaN  108.0  100.0  ...   \n",
       "465                   R                NaN  104.0   97.0  ...   \n",
       "467                   R                NaN  127.0  121.0  ...   \n",
       "471                   R                NaN  134.0  131.0  ...   \n",
       "\n",
       "     WISC_IV_DIGIT_SPAN_SCALED WISC_IV_LET_NUM_SCALED WISC_IV_CODING_SCALED  \\\n",
       "460                        NaN                    NaN                   NaN   \n",
       "464                        NaN                    NaN                   NaN   \n",
       "465                        NaN                    NaN                   NaN   \n",
       "467                        NaN                    NaN                   NaN   \n",
       "471                        NaN                    NaN                   NaN   \n",
       "\n",
       "    WISC_IV_SYM_SCALED  EYE_STATUS_AT_SCAN  AGE_AT_MPRAGE  BMI  \\\n",
       "460                NaN                   2            NaN  NaN   \n",
       "464                NaN                   2            NaN  NaN   \n",
       "465                NaN                   2            NaN  NaN   \n",
       "467                NaN                   2            NaN  NaN   \n",
       "471                NaN                   2            NaN  NaN   \n",
       "\n",
       "         bids_folder  site                           funcFile  \n",
       "460  sub-CMUa0050642     1  CMU_a_0050642_func_preproc.nii.gz  \n",
       "464  sub-CMUa0050646     1  CMU_a_0050646_func_preproc.nii.gz  \n",
       "465  sub-CMUa0050647     1  CMU_a_0050647_func_preproc.nii.gz  \n",
       "467  sub-CMUa0050649     1  CMU_a_0050649_func_preproc.nii.gz  \n",
       "471  sub-CMUa0050653     1  CMU_a_0050653_func_preproc.nii.gz  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/ABIDE_df3.csv')\n",
    "df = df.iloc[~pd.isna(df['bids_folder']).values]\n",
    "df = df.sort_values(by='bids_folder')\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../Assets/glasser2016_cmats/filt_noglobal/cmat/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048, 360, 360)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmats = np.array([np.load(data_dir+str(val)+'.npy') for val in df['participant_id'].values])\n",
    "cmats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlbls = pd.read_csv('../Data/GlasserAtlas/glasser360NodeNames.txt',header=None)\n",
    "rlbls = rlbls[0].to_list()\n",
    "rlbls = np.array(rlbls)\n",
    "drop_rois = np.array(['Left_OFC', 'Right_TGv', 'Right_OFC', 'Left_TGv', 'Right_s32',\n",
    "       'Left_s32', 'Left_pOFC', 'Right_25', 'Left_25', 'Right_LO2',\n",
    "       'Right_TE1m', 'Right_pOFC', 'Left_10pp', 'Right_PIT', 'Right_13l',\n",
    "       'Left_LO2', 'Left_PIT', 'Left_7AL', 'Right_PeEc', 'Right_TE2a',\n",
    "       'Left_TE2a', 'Right_10pp', 'Right_10v', 'Right_47m'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336\n",
      "(1048, 336, 336)\n"
     ]
    }
   ],
   "source": [
    "# Slice ROIs\n",
    "rslice = np.array([rlbl not in drop_rois for rlbl in rlbls])\n",
    "print(rslice.sum())\n",
    "\n",
    "cmats = np.array([cmats[i,:,:][rslice,:][:,rslice] for i in range(cmats.shape[0])])\n",
    "print(cmats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop subjects with NaNs\n",
    "no_nans = np.isnan(cmats).sum(-1).sum(-1)==0\n",
    "cmats = cmats[no_nans,:,:]\n",
    "df = df.iloc[no_nans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize to 0-1\n",
    "cmats = (cmats+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.033334957297894874, 1.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cmats.min(),cmats.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(336,)\n",
      "CPU times: user 11.2 s, sys: 1.39 s, total: 12.6 s\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Reliability data\n",
    "\n",
    "\n",
    "# Load list of bad ROIs\n",
    "bad_rois = pd.read_csv('../Data/GlasserAtlas/bad_rois.csv')\n",
    "bad_rois.head()\n",
    "\n",
    "# Load Rel data\n",
    "rel_data = np.load('../Assets/glasser2016_cmats/filt_noglobal/rel-cmats.npz')['rel_cmats']\n",
    "patients = df['DX_GROUP'].values==1 \n",
    "rel_asd = rel_data[no_nans,:,:,:][patients,:,:,:] #only asd subjects\n",
    "del rel_data\n",
    "\n",
    "rel_rlbls = rlbls.copy() \n",
    "v = np.array([rel_rlbl not in bad_rois['rlbl'].values[0:12] for rel_rlbl in rel_rlbls]) #initia slice to 348\n",
    "rel_rlbls = rel_rlbls[v]\n",
    "\n",
    "v = np.array([rel_rlbl not in bad_rois['rlbl'].values[0:24] for rel_rlbl in rel_rlbls]) # second slice to 336\n",
    "rel_rlbls = rel_rlbls[v]\n",
    "\n",
    "rel_asd = rel_asd[:,v,:,:][:,:,v,:]\n",
    "rel_asd1 = rel_asd[:,:,:,0] # first half \n",
    "rel_asd2 = rel_asd[:,:,:,1] # second half \n",
    "\n",
    "print(rel_rlbls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END OF DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52 ms, sys: 9.46 ms, total: 61.5 ms\n",
      "Wall time: 259 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow' from '/data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/__init__.py'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from importlib import reload\n",
    "import helper_funcs;reload(helper_funcs);from helper_funcs import *\n",
    "del helper_funcs\n",
    "import make_models;reload(make_models);from make_models import *\n",
    "del make_models\n",
    "\n",
    "from IPython import display\n",
    "import sys\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "reload(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1042, 336, 336)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cvae_data_loader():\n",
    "    ''' this is the info'''\n",
    "    def __init__(self,data,df,batch_size=32):\n",
    "        self.n = len(df)\n",
    "        self.data = data\n",
    "        self.epoch = -1\n",
    "        self.batch_size = batch_size\n",
    "        self.df = df\n",
    "        \n",
    "        self.new_epoch()\n",
    "        self.n_batches = int(np.floor(min((len(self.asd_idxs),len(self.td_idxs)))/self.batch_size))\n",
    "        \n",
    "    def new_epoch(self):\n",
    "        \n",
    "        self.asd_idxs = np.nonzero((self.df['DX_GROUP'].values==1))[0]\n",
    "        self.td_idxs = np.nonzero((self.df['DX_GROUP'].values==2))[0]\n",
    "        \n",
    "        self.asd_idxs = np.random.permutation(self.asd_idxs)\n",
    "        self.td_idxs = np.random.permutation(self.td_idxs)\n",
    "        \n",
    "        self.epoch += 1\n",
    "        self.b = 0\n",
    "        \n",
    "    def get_batch(self):\n",
    "        self.b += 1\n",
    "        \n",
    "        if self.b==self.n_batches:\n",
    "            self.new_epoch()\n",
    "        \n",
    "        self.batch_asd_idx = self.asd_idxs[np.arange(self.b*self.batch_size,self.b*self.batch_size+self.batch_size)]\n",
    "        self.batch_td_idx = self.td_idxs[np.arange(self.b*self.batch_size,self.b*self.batch_size+self.batch_size)]\n",
    "        \n",
    "        self.batch_asd = self.data[self.batch_asd_idx,:,:]\n",
    "        self.batch_td = self.data[self.batch_td_idx,:,:]\n",
    "\n",
    "#         self.batch_asd = np.array([np.load(os.path.join(self.data_dir,val+'.npy')) for val in self.df['bids_folder'].values[self.batch_asd_idx]])\n",
    "#         self.batch_td = np.array([np.load(os.path.join(self.data_dir,val+'.npy')) for val in self.df['bids_folder'].values[self.batch_td_idx]])\n",
    "        \n",
    "        self.batch_df = self.df.iloc[np.hstack((self.batch_asd_idx,self.batch_td_idx)),:]\n",
    "        \n",
    "    \n",
    "        return self.batch_asd,self.batch_td,self.batch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PADDING\n",
    "#pad2d = tf.keras.layers.ZeroPadding2D(padding=((6,7),(6,7))) #If tuple of 2 tuples of 2 ints: interpreted as ((top_pad, bottom_pad), (left_pad, right_pad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = cvae_data_loader(data=cmats, df=df, batch_size=32)\n",
    "batch_asd,batch_td,batch_df = data_loader.get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12367952262235965, 1.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(batch_asd.min(),batch_asd.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1042,  336,  336])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_size = np.hstack((len(df),batch_asd.shape[1:]))\n",
    "data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patients = df['DX_GROUP'].values==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSA\n",
    "\n",
    "\n",
    "#cdata = np.array([np.load(os.path.join(data_dir,sub+'.npy')) for sub in df['bids_folder'].values[patients]])\n",
    "#cdata_pad = pad2d(cdata[:,:,:,np.newaxis]).numpy()[:,:,:,:]\n",
    "\n",
    "def get_batch_RSA():\n",
    "    \n",
    "    patients = ~np.isnan(df['ADOS_TOTAL'].values) * (df['DX_GROUP'].values==1) * ~np.isnan(df['FIQ'].values)\n",
    "    cdata = cmats[patients,:,:]\n",
    "    cdata_pad = cdata\n",
    "    #cdata_pad[patients,:,:]\n",
    "\n",
    "    Z = z_encoder.predict(cdata_pad)\n",
    "    S = s_encoder.predict(cdata_pad)\n",
    "\n",
    "    rdm_z = make_RDM(Z[2])\n",
    "    rdm_s = make_RDM(S[2])\n",
    "\n",
    "    rdm_age = make_RDM(df['AGE_AT_SCAN'].values[patients])\n",
    "    rdm_sex = make_RDM(df['SEX'].values[patients],data_scale='ordinal')\n",
    "    rdm_fiq = make_RDM(df['FIQ'].values[patients])\n",
    "    rdm_dsm = make_RDM(df['DSM_IV_TR'].values[patients],data_scale='ordinal')\n",
    "    rdm_site = make_RDM(df['site'].values[patients],data_scale='ordinal')\n",
    "    rdm_adosTotal = make_RDM(df['ADOS_TOTAL'].values[patients])\n",
    "    \n",
    "    \n",
    "    batch_rsas_s = dict()\n",
    "    batch_rsas_z = dict()\n",
    "    \n",
    "    \n",
    "    batch_rsas_s['Site'] = fit_rsa(rdm_s,rdm_site)\n",
    "    batch_rsas_s['Age'] = fit_rsa(rdm_s,rdm_age)\n",
    "    batch_rsas_s['Sex'] = fit_rsa(rdm_s,rdm_sex)\n",
    "    batch_rsas_s['DSM'] = fit_rsa(rdm_s,rdm_dsm)\n",
    "    batch_rsas_s['ADOS'] = fit_rsa(rdm_s,rdm_adosTotal)\n",
    "    batch_rsas_s['FIQ'] = fit_rsa(rdm_s,rdm_fiq)\n",
    "\n",
    "    batch_rsas_z['Site'] = fit_rsa(rdm_z,rdm_site)\n",
    "    batch_rsas_z['Age'] = fit_rsa(rdm_z,rdm_age)\n",
    "    batch_rsas_z['Sex'] = fit_rsa(rdm_z,rdm_sex)\n",
    "    batch_rsas_z['DSM'] = fit_rsa(rdm_z,rdm_dsm)\n",
    "    batch_rsas_z['ADOS'] = fit_rsa(rdm_z,rdm_adosTotal)\n",
    "    batch_rsas_z['FIQ'] = fit_rsa(rdm_z,rdm_fiq)\n",
    "    \n",
    "    batch_rsas = dict()\n",
    "    batch_rsas['batch_rsas_z'] = batch_rsas_z\n",
    "    batch_rsas['batch_rsas_s'] = batch_rsas_s\n",
    "    \n",
    "    return batch_rsas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rel(mat1,mat2):\n",
    "    \n",
    "    from scipy.spatial.distance import pdist,squareform\n",
    "\n",
    "    #mat1 = S_rel1\n",
    "    #mat2 = S_rel2\n",
    "\n",
    "    D = squareform(pdist(np.vstack([mat1,mat2])))\n",
    "    first_second_dist = D[0:mat1.shape[0],:][:,mat1.shape[0]::]\n",
    "\n",
    "    ranks = []\n",
    "    for s in range(first_second_dist.shape[0]):\n",
    "        vec = first_second_dist[s,:]\n",
    "        within = vec[s]\n",
    "        across = vec[np.arange(len(vec))!=s]\n",
    "        rank = (across < within).sum()+1\n",
    "        ranks.append(rank)\n",
    "\n",
    "    ranks = np.array(ranks)\n",
    "    \n",
    "#     print(np.median(ranks))\n",
    "#     print((ranks==1).mean())\n",
    "    \n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvae_dashboard(red='PCA'):        \n",
    "    #prediction = cvae.predict(patient_batch)    \n",
    "    predictions = cvae.predict([patient_batch,control_batch])\n",
    "    sigma = (np.e ** z_encoder.predict(patient_batch)[1]).mean()\n",
    "    sigmas.append(sigma)\n",
    "\n",
    "    \n",
    "    ss = 6;ff=57\n",
    "    \n",
    "    mu = z_encoder.predict(patient_batch)[0]\n",
    "    mus.append(np.mean([mu[:,0].std() for i in range(mu.shape[1])]))\n",
    "\n",
    "    prediction = predictions[0]\n",
    "\n",
    "    cmat_actual = np.corrcoef(np.vstack((patient_batch[:,ss:ff,ss:ff].reshape(patient_batch.shape[0],-1),control_batch[:,ss:ff,ss:ff].reshape(control_batch.shape[0],-1))))\n",
    "    cmat_pred = np.corrcoef(np.vstack((predictions[0][:,ss:ff,ss:ff,:].reshape(predictions[0].shape[0],-1),predictions[1][:,ss:ff,ss:ff,:].reshape(predictions[1].shape[0],-1))))\n",
    "    c_sim.append(np.corrcoef(get_triu(cmat_pred),get_triu(cmat_actual))[0,1])\n",
    "\n",
    "\n",
    "    ### PROGRESS PLOTTING\n",
    "    display.clear_output(wait=True);\n",
    "    display.display(plt.gcf());\n",
    "    #Organise figure\n",
    "    ncols = 4;nrows=7\n",
    "    if np.mod(i,5)==0:\n",
    "        plt.close()\n",
    "    plt.subplots(nrows,ncols,figsize=(15,15)); # MAKE THE FIGURE\n",
    "\n",
    "\n",
    "    ##### SUBPLOT 1 & 2 ##### \n",
    "\n",
    "    plt.subplot(nrows,ncols/2,1) # PLOT LOSS\n",
    "    xs = np.arange(len(loss))+1\n",
    "    m,b = np.polyfit(xs,loss,deg=1)\n",
    "    plt.plot(loss)\n",
    "    plt.plot(xs, m*xs + b)\n",
    "    plt.title(f'Epoch {data_loader.epoch} batch {data_loader.b}/{data_loader.n_batches} | Loss {loss[-1]:.2f}, beta: {m:.4f}')\n",
    "\n",
    "    ##### SUBPLOT 3 ##### \n",
    "    plt.subplot(nrows,ncols,3) # PLOT LOSS LAST 50\n",
    "    hb = 50\n",
    "    if len(loss)>hb:\n",
    "        plot_loss = loss[-hb::]\n",
    "        xs = np.arange(len(plot_loss))\n",
    "        m,b = np.polyfit(xs,plot_loss,deg=1)\n",
    "        plt.plot(plot_loss)\n",
    "        plt.plot(xs, m*xs + b)\n",
    "        #plt.title(hist)\n",
    "        plt.title(f'Loss last {hb} it, beta {m:.4f}')\n",
    "\n",
    "    ##### SUBPLOT 4 ##### \n",
    "    plt.subplot(nrows,ncols,4)\n",
    "    plt.hist(prediction[0,ss:ff,ss:ff,0].flatten(),alpha=.5)\n",
    "    plt.hist(patient_batch[0,ss:ff,ss:ff].flatten(),alpha=.5)\n",
    "    plt.legend(['predicted','actual'])\n",
    "    plt.title('in/out histograms')\n",
    "\n",
    "    ##### SUBPLOT 5 ##### \n",
    "    plt.subplot(nrows,ncols,5) #RSA over time\n",
    "    plt.plot(c_sim)\n",
    "    plt.title(f'in/out RSA: {c_sim[-1].round(2)}')\n",
    "\n",
    "    if len(c_sim)>5: # PLOT LS LINE\n",
    "        xs = np.arange(len(c_sim))+1\n",
    "        m,b = np.polyfit(xs,c_sim,deg=1)\n",
    "        plt.plot(xs, m*xs + b)\n",
    "        plt.title(f'in/out RSA: {c_sim[-1].round(2)}, b={m:.4f}')\n",
    "\n",
    "\n",
    "    ##### SUBPLOT 6 ##### \n",
    "    plt.subplot(nrows,ncols,6)\n",
    "    if len(c_sim)>hb:\n",
    "        #plot_loss = loss[-hb::]\n",
    "        xs = np.arange(len(c_sim[-hb::]))\n",
    "        m,b = np.polyfit(xs,c_sim[-hb::],deg=1)\n",
    "        plt.plot(c_sim[-hb::])\n",
    "        plt.plot(xs, m*xs + b)\n",
    "        #plt.title(hist)\n",
    "        plt.title(f'in/outRSA last {hb} it, b={m:.4f}')\n",
    "        \n",
    "        \n",
    "        \n",
    "    batch_rsas = get_batch_RSA()\n",
    "    batch_rsas_z = batch_rsas['batch_rsas_z']\n",
    "    batch_rsas_s = batch_rsas['batch_rsas_s']\n",
    "    \n",
    "    # ##### SUBPLOT 7 ##### \n",
    "    plt.subplot(nrows,ncols,7)    \n",
    "    xlbls = list(batch_rsas_z.keys())\n",
    "    xs = np.arange(len(xlbls))\n",
    "    ys = np.array([batch_rsas_z[key] for key in xlbls])\n",
    "    plt.bar(xs,ys)\n",
    "    plt.xticks(xs,labels=xlbls);\n",
    "    plt.title('Z RSA')\n",
    "    \n",
    "    # ##### SUBPLOT 8 ##### \n",
    "    plt.subplot(nrows,ncols,8)    \n",
    "    xlbls = list(batch_rsas_s.keys())\n",
    "    xs = np.arange(len(xlbls))\n",
    "    ys = np.array([batch_rsas_s[key] for key in xlbls])\n",
    "    plt.bar(xs,ys)\n",
    "    plt.xticks(xs,labels=xlbls);\n",
    "    plt.title('S RSA')\n",
    "\n",
    "    ##### SUBPLOT 9 ##### \n",
    "    plt.subplot(nrows,ncols,9)\n",
    "    plt.plot(sigmas)\n",
    "    plt.title(f'sigmas | {sigmas[-1]:.4f}')\n",
    "\n",
    "\n",
    "    ##### SUBPLOT 10 ##### \n",
    "    plt.subplot(nrows,ncols,10)\n",
    "    plt.plot(mus)\n",
    "    plt.title(f'Mu variance {mus[-1]:.4f}')\n",
    "\n",
    "\n",
    "    ##### SUBPLOT 11 ##### \n",
    "    plt.subplot(nrows,ncols,11)\n",
    "    sns.heatmap(cmat_actual,xticklabels=[],yticklabels=[])\n",
    "    plt.title('input RSA')\n",
    "\n",
    "    ##### SUBPLOT 12 ##### \n",
    "    plt.subplot(nrows,ncols,12)\n",
    "    sns.heatmap(cmat_pred,xticklabels=[],yticklabels=[])\n",
    "    plt.title('output RSA')\n",
    "\n",
    "    # #############################################\n",
    "    # ###################Reconstructions###########\n",
    "    # #############################################\n",
    "\n",
    "    ##### SUBPLOT 13 #####     \n",
    "    rand_sub = np.random.randint(low=0,high=patient_batch.shape[0])\n",
    "\n",
    "    plt.subplot(nrows,ncols,13)\n",
    "    sns.heatmap(patient_batch[rand_sub,ss:ff,ss:ff])\n",
    "    plt.xticks([]);plt.yticks([]);plt.title('actual')\n",
    "    ##### SUBPLOT 14 #####     \n",
    "    plt.subplot(nrows,ncols,14)\n",
    "    sns.heatmap(prediction[rand_sub,ss:ff,ss:ff,0])\n",
    "    plt.xticks([]);plt.yticks([]);plt.title('predicted')\n",
    "    # ##### SUBPLOT 15 #####     \n",
    "    plt.subplot(nrows,ncols,15)\n",
    "    sns.heatmap(abs(patient_batch[rand_sub,ss:ff,ss:ff]-prediction[rand_sub,ss:ff,ss:ff,0]))\n",
    "    plt.xticks([]);plt.yticks([]);plt.title('difference')\n",
    "    \n",
    "    \n",
    "    # ##### SUBPLOT 16 #####                                             \n",
    "\n",
    "\n",
    "    # ##### SUBPLOT 17 #####                             \n",
    "    plt.subplot(nrows,ncols,17)\n",
    "    Z_rel1 = z_encoder.predict(rel_asd1)[0]\n",
    "    Z_rel2 = z_encoder.predict(rel_asd2)[0]\n",
    "    z_ranks.append(np.median(calc_rel(Z_rel1,Z_rel2)))\n",
    "    plt.plot(z_ranks)\n",
    "    plt.title(f'Z rel\\nmed rank = {int(np.median(z_ranks))}, rank1 acc = {(np.array(z_ranks)==1).mean():.4f}')\n",
    "\n",
    "    # ##### SUBPLOT 18 #####     \n",
    "    plt.subplot(nrows,ncols,18)\n",
    "    S_rel1 = s_encoder.predict(rel_asd1)[0]\n",
    "    S_rel2 = s_encoder.predict(rel_asd2)[0]\n",
    "    s_ranks.append(np.median(calc_rel(S_rel1,S_rel2)))\n",
    "    plt.plot(s_ranks)\n",
    "    plt.title(f'S rel\\nmed rank = {int(np.median(s_ranks))}, rank1 acc = {(np.array(s_ranks)==1).mean():.4f}')\n",
    "    \n",
    "    \n",
    "    # ##### SUBPLOT 18 #####                                             \n",
    "    # ##### SUBPLOT 19 #####     \n",
    "    # plt.subplot(nrows,ncols,19)\n",
    "    # plt.imshow(patient_batch[rand_sub,:,:,16,rand_map])\n",
    "    # plt.xticks([]);plt.yticks([]);plt.title('actual')\n",
    "    # ##### SUBPLOT 20 #####     \n",
    "    # plt.subplot(nrows,ncols,20)\n",
    "    # plt.imshow(prediction[rand_sub,:,:,16,rand_map])\n",
    "    # plt.xticks([]);plt.yticks([]);plt.title('predicted')\n",
    "\n",
    "\n",
    "    # #############################################\n",
    "    # ################### LOSSES ##################\n",
    "    # #############################################\n",
    "\n",
    "\n",
    "    predictions = cvae.predict([patient_batch,control_batch])\n",
    "    input_shape = data_size[1:]\n",
    "    reconstruction_loss = tf.keras.losses.mse(K.flatten(patient_batch[:,ss:ff,ss:ff]), K.flatten(predictions[0][:,ss:ff,ss:ff,0])) \n",
    "    reconstruction_loss += tf.keras.losses.mse(K.flatten(control_batch[:,ss:ff,ss:ff]), K.flatten(predictions[1][:,ss:ff,ss:ff,0])) \n",
    "    reconstruction_loss *= input_shape[0] * input_shape[1]\n",
    "\n",
    "\n",
    "    tg_z_mean, tg_z_log_var, tg_z = z_encoder.predict(patient_batch)\n",
    "    tg_s_mean, tg_s_log_var, tg_s = s_encoder.predict(patient_batch)\n",
    "    bg_z_mean, bg_z_log_var, bg_z = z_encoder.predict(control_batch)\n",
    "\n",
    "    kl_loss1 = 1 + tg_z_log_var - tf.keras.backend.square(tg_z_mean) - tf.keras.backend.exp(tg_z_log_var)\n",
    "    kl_loss2 = 1 + tg_s_log_var - tf.keras.backend.square(tg_s_mean) - tf.keras.backend.exp(tg_s_log_var)\n",
    "    kl_loss3 = 1 + bg_z_log_var - tf.keras.backend.square(bg_z_mean) - tf.keras.backend.exp(bg_z_log_var)\n",
    "\n",
    "    kl_loss1 = tf.keras.backend.sum(kl_loss1, axis=-1)\n",
    "    kl_loss2 = tf.keras.backend.sum(kl_loss2, axis=-1)\n",
    "    kl_loss3 = tf.keras.backend.sum(kl_loss3, axis=-1)\n",
    "    kl_loss = kl_loss1+kl_loss2+kl_loss3\n",
    "    kl_loss *= -0.5\n",
    "\n",
    "\n",
    "    discriminator = Dense(1, activation='sigmoid')\n",
    "    z1 = Lambda(lambda x: x[:int(batch_size/2),:])(tg_z)\n",
    "    z2 = Lambda(lambda x: x[int(batch_size/2):,:])(tg_z)\n",
    "    s1 = Lambda(lambda x: x[:int(batch_size/2),:])(tg_s)\n",
    "    s2 = Lambda(lambda x: x[int(batch_size/2):,:])(tg_s)\n",
    "\n",
    "    q_bar = tf.keras.layers.concatenate(\n",
    "      [tf.keras.layers.concatenate([s1, z2], axis=1),\n",
    "      tf.keras.layers.concatenate([s2, z1], axis=1)],\n",
    "      axis=0)\n",
    "\n",
    "    q = tf.keras.layers.concatenate(\n",
    "      [tf.keras.layers.concatenate([s1, z1], axis=1),\n",
    "      tf.keras.layers.concatenate([s2, z2], axis=1)],\n",
    "      axis=0)\n",
    "\n",
    "    q_bar_score = (discriminator(q_bar)+.1) *.85 # +.1 * .85 so that it's 0<x<1\n",
    "    q_score = (discriminator(q)+.1) *.85 \n",
    "    tc_loss = K.log(q_score / (1 - q_score)) \n",
    "    discriminator_loss = - K.log(q_score) - K.log(1 - q_bar_score)\n",
    "    discriminator_loss\n",
    "\n",
    "    loss_mse.append(reconstruction_loss.numpy())\n",
    "    loss_kl.append(kl_loss.numpy().mean())\n",
    "    loss_dc.append(tc_loss.numpy().mean())\n",
    "    loss_tc.append(discriminator_loss.numpy().mean())\n",
    "\n",
    "\n",
    "    plt.subplot(nrows,ncols,21) # MSE \n",
    "    plt.plot(loss_mse)\n",
    "    plt.title(f'MSE | {loss_mse[-1]:.4f}')\n",
    "\n",
    "    plt.subplot(nrows,ncols,22) # KL loss\n",
    "    plt.plot(loss_kl)\n",
    "    plt.title(f'KL | {loss_kl[-1]:.4f}')    \n",
    "\n",
    "\n",
    "    plt.subplot(nrows,ncols,23) # TC     \n",
    "    plt.plot(loss_tc)\n",
    "    plt.title(f'Total Correlation loss | {loss_tc[-1]:.4f}')    \n",
    "\n",
    "\n",
    "    plt.subplot(nrows,ncols,24) # Disc         \n",
    "    plt.plot(loss_dc)\n",
    "    plt.title(f'discriminator_loss | {loss_dc[-1]:.4f}')    \n",
    "\n",
    "\n",
    "    tg_s = s_encoder.predict(patient_batch)\n",
    "    tg_z = z_encoder.predict(patient_batch)\n",
    "    bg_z = z_encoder.predict(control_batch)\n",
    "\n",
    "    plt.subplot(nrows,ncols,25)\n",
    "    plt.hist(tg_s[2].flatten(),alpha=.5);\n",
    "    plt.hist(tg_z[2].flatten(),alpha=.5);\n",
    "    plt.hist(bg_z[2].flatten(),alpha=.5);\n",
    "    plt.legend(['tg_s','tg_z','bg_z'])\n",
    "    plt.title('Z')\n",
    "\n",
    "\n",
    "    plt.subplot(nrows,ncols,26)\n",
    "    plt.hist(tg_s[0].flatten(),alpha=.5);\n",
    "    plt.hist(tg_z[0].flatten(),alpha=.5);\n",
    "    plt.hist(bg_z[0].flatten(),alpha=.5);\n",
    "    plt.legend(['tg_s','tg_z','bg_z'])\n",
    "    plt.title('Mus')\n",
    "\n",
    "\n",
    "    plt.subplot(nrows,ncols,27)\n",
    "    plt.hist(tg_s[1].flatten(),alpha=.5);\n",
    "    plt.hist(tg_z[1].flatten(),alpha=.5);\n",
    "    plt.hist(bg_z[1].flatten(),alpha=.5);\n",
    "    plt.legend(['tg_s','tg_z','bg_z'])\n",
    "    plt.title('Sigmas')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import mse\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_fMRI_CVAE_3D(input_shape=(51,51,1),\n",
    "                     latent_dim=[2,2],\n",
    "                     beta=1,\n",
    "                     disentangle=False,\n",
    "                     gamma=1,\n",
    "                     bias=True,\n",
    "                     batch_size = 32,\n",
    "                     kernel_size = 3,\n",
    "                     filters = 16,\n",
    "                     intermediate_dim = 128,\n",
    "                     nlayers = 2,\n",
    "                     learning_rate=0.001,\n",
    "                     opt=None):\n",
    "    \n",
    "    \n",
    "    ndim_bg = latent_dim[0]\n",
    "    ndim_sl = latent_dim[1]\n",
    "    \n",
    "    image_size, _, channels = input_shape\n",
    "\n",
    "    kernel_regularizer=regularizers.l2(.0001)\n",
    "\n",
    "    # build encoder model\n",
    "    tg_inputs = Input(shape=input_shape, name='tg_inputs')\n",
    "    bg_inputs = Input(shape=input_shape, name='bg_inputs')\n",
    "    \n",
    "#     BatchNorm = tf.keras.layers.BatchNormalization(\n",
    "#     axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True,\n",
    "#     beta_initializer='zeros', gamma_initializer='ones',\n",
    "#     moving_mean_initializer='zeros',\n",
    "#     moving_variance_initializer='ones', beta_regularizer=None,\n",
    "#     gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "\n",
    "    #kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0,stddev=5)\n",
    "    kernel_initializer = tf.keras.initializers.RandomUniform()\n",
    "\n",
    "    # generate latent vector Q(z|X)\n",
    "    \n",
    "    \n",
    "    z_h_layer = Dense(intermediate_dim,activation='relu', use_bias=bias,kernel_regularizer=kernel_regularizer)\n",
    "#    z_h_layer = Dense(intermediate_dim, activation='relu', use_bias=bias,kernel_regularizer=kernel_regularizer,kernel_initializer=tf.keras.initializers.random_normal(mean=0.0, stddev=5),bias_initializer=tf.keras.initializers.random_normal(mean=0.0, stddev=5))\n",
    "    z_mean_layer = Dense(ndim_bg, name='z_mean', use_bias=bias,kernel_regularizer=kernel_regularizer)\n",
    "    z_log_var_layer = Dense(ndim_bg, name='z_log_var', use_bias=bias,kernel_regularizer=kernel_regularizer)\n",
    "    z_layer = Lambda(sampling, output_shape=(ndim_bg,), name='z')\n",
    "\n",
    "    def z_encoder_func(inputs):\n",
    "        z_h = inputs\n",
    "\n",
    "        these_filters = filters\n",
    "        for i in range(nlayers):\n",
    "            these_filters *= 2\n",
    "            #print(these_filters)\n",
    "            z_h = Conv2D(filters=these_filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    activation='relu',\n",
    "                    strides=2,\n",
    "                    padding='same',\n",
    "                    use_bias=bias,\n",
    "                    kernel_regularizer=kernel_regularizer)(z_h)\n",
    "        \n",
    "        # shape info needed to build decoder model\n",
    "        shape = K.int_shape(z_h)\n",
    "        z_h = Flatten()(z_h)\n",
    "        z_h = z_h_layer(z_h)\n",
    "        z_mean =  z_mean_layer(z_h)\n",
    "        #z_mean = BatchNorm(z_mean)\n",
    "        \n",
    "        z_log_var =  z_log_var_layer(z_h)\n",
    "        z = z_layer([z_mean, z_log_var])\n",
    "        return z_mean, z_log_var, z, shape\n",
    "\n",
    "    tg_z_mean, tg_z_log_var, tg_z, shape_z = z_encoder_func(tg_inputs)\n",
    "\n",
    "    # generate latent vector Q(z|X)\n",
    "    s_h_layer = Dense(intermediate_dim, activation='relu', use_bias=bias,kernel_regularizer=kernel_regularizer)\n",
    "#    s_h_layer = Dense(intermediate_dim, activation='relu', use_bias=bias,kernel_regularizer=kernel_regularizer,kernel_initializer=tf.keras.initializers.random_normal(mean=0.0, stddev=5),bias_initializer=tf.keras.initializers.random_normal(mean=0.0, stddev=5))\n",
    "    s_mean_layer = Dense(ndim_sl, name='s_mean', use_bias=bias,kernel_regularizer=kernel_regularizer)\n",
    "    s_log_var_layer = Dense(ndim_sl, name='s_log_var', use_bias=bias,kernel_regularizer=kernel_regularizer)\n",
    "    s_layer = Lambda(sampling, output_shape=(ndim_sl,), name='s')\n",
    "\n",
    "    def s_encoder_func(inputs):\n",
    "        s_h = inputs\n",
    "        these_filters = filters\n",
    "        for i in range(nlayers):\n",
    "            these_filters *= 2\n",
    "            s_h = Conv2D(filters=these_filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    activation='relu',\n",
    "                    strides=2,\n",
    "                    use_bias=bias,\n",
    "                    kernel_regularizer=kernel_regularizer,\n",
    "                    padding='same')(s_h)\n",
    "        \n",
    "        # shape info needed to build decoder model\n",
    "        shape = K.int_shape(s_h)\n",
    "        s_h = Flatten()(s_h)\n",
    "        s_h = s_h_layer(s_h)\n",
    "        s_mean =  s_mean_layer(s_h)\n",
    "        #s_mean = BatchNorm(s_mean)\n",
    "        \n",
    "        s_log_var =  s_log_var_layer(s_h)        \n",
    "        s = s_layer([s_mean, s_log_var])\n",
    "        \n",
    "        return s_mean, s_log_var, s, shape\n",
    "\n",
    "    tg_s_mean, tg_s_log_var, tg_s, shape_s = s_encoder_func(tg_inputs)\n",
    "    bg_z_mean, bg_z_log_var, bg_z, _ = z_encoder_func(bg_inputs) # Aidas and Stefano team hax\n",
    "    \n",
    "    \n",
    "    # instantiate encoder models\n",
    "    z_encoder = tf.keras.models.Model(tg_inputs, [tg_z_mean, tg_z_log_var, tg_z], name='z_encoder')\n",
    "    s_encoder = tf.keras.models.Model(tg_inputs, [tg_s_mean, tg_s_log_var, tg_s], name='s_encoder')\n",
    "\n",
    "\n",
    "    # build decoder model\n",
    "    latent_inputs = Input(shape=(ndim_bg+ndim_sl,), name='z_sampling')\n",
    "\n",
    "    x = Dense(intermediate_dim, activation='relu', use_bias=bias,kernel_regularizer=kernel_regularizer,kernel_initializer=kernel_initializer)(latent_inputs)\n",
    "    x = Dense(shape_z[1] * shape_z[2] * shape_z[3], activation='relu', use_bias=bias,kernel_regularizer=kernel_regularizer,kernel_initializer=kernel_initializer)(x)\n",
    "    x = Reshape((shape_z[1], shape_z[2], shape_z[3]))(x)\n",
    "\n",
    "    these_filters = filters*(2**nlayers)/2\n",
    "    for i in range(nlayers-1):\n",
    "        x = Conv2DTranspose(filters=these_filters,\n",
    "                          kernel_size=kernel_size,\n",
    "                          activation='relu',\n",
    "                          strides=2,\n",
    "                          use_bias=bias,\n",
    "                          kernel_regularizer=kernel_regularizer,\n",
    "                          padding='same')(x)\n",
    "        these_filters //= 2\n",
    "\n",
    "    outputs = Conv2DTranspose(filters=channels,\n",
    "                            kernel_size=kernel_size,\n",
    "                            activation='sigmoid',\n",
    "                            padding='same',\n",
    "                            strides=2,\n",
    "                            use_bias=bias,\n",
    "                            kernel_regularizer=kernel_regularizer,\n",
    "                            name='decoder_output')(x)\n",
    "\n",
    "    # instantiate decoder model\n",
    "    cvae_decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "      # decoder.summary()\n",
    "\n",
    "    def zeros_like(x):\n",
    "        return tf.zeros_like(x)\n",
    "\n",
    "    tg_outputs = cvae_decoder(tf.keras.layers.concatenate([tg_z, tg_s], -1))\n",
    "    zeros = tf.keras.layers.Lambda(zeros_like)(tg_s)\n",
    "\n",
    "    bg_outputs = cvae_decoder(tf.keras.layers.concatenate([bg_z, zeros], -1)) # Aidas look into this, is this correct\n",
    "\n",
    "    cvae = tf.keras.models.Model(inputs=[tg_inputs, bg_inputs], \n",
    "                                  outputs=[tg_outputs, bg_outputs],\n",
    "                                  name='contrastive_vae')\n",
    "\n",
    "#     cvae_fg = tf.keras.models.Model(inputs=tg_inputs, \n",
    "#                                   outputs=fg_outputs, \n",
    "#                                   name='contrastive_vae_fg')\n",
    "\n",
    "    if disentangle:\n",
    "        discriminator = Dense(1, activation='sigmoid')\n",
    "\n",
    "        z1 = Lambda(lambda x: x[:int(batch_size/2),:])(tg_z)\n",
    "        z2 = Lambda(lambda x: x[int(batch_size/2):,:])(tg_z)\n",
    "        s1 = Lambda(lambda x: x[:int(batch_size/2),:])(tg_s)\n",
    "        s2 = Lambda(lambda x: x[int(batch_size/2):,:])(tg_s)\n",
    "\n",
    "        q_bar = tf.keras.layers.concatenate(\n",
    "          [tf.keras.layers.concatenate([s1, z2], axis=1),\n",
    "          tf.keras.layers.concatenate([s2, z1], axis=1)],\n",
    "          axis=0)\n",
    "\n",
    "        q = tf.keras.layers.concatenate(\n",
    "          [tf.keras.layers.concatenate([s1, z1], axis=1),\n",
    "          tf.keras.layers.concatenate([s2, z2], axis=1)],\n",
    "          axis=0)\n",
    "\n",
    "        q_bar_score = (discriminator(q_bar)+.1) *.85 # +.1 * .85 so that it's 0<x<1\n",
    "        q_score = (discriminator(q)+.1) *.85 \n",
    "        tc_loss = K.log(q_score / (1 - q_score)) \n",
    "        discriminator_loss = - K.log(q_score) - K.log(1 - q_bar_score)\n",
    "    else:\n",
    "        tc_loss = 0\n",
    "        discriminator_loss = 0\n",
    "\n",
    "\n",
    "    reconstruction_loss = tf.keras.losses.mse(K.flatten(tg_inputs), K.flatten(tg_outputs)) \n",
    "    reconstruction_loss += tf.keras.losses.mse(K.flatten(bg_inputs), K.flatten(bg_outputs)) \n",
    "    reconstruction_loss *= input_shape[0] * input_shape[1] * input_shape[2]\n",
    "\n",
    "    kl_loss1 = 1 + tg_z_log_var - tf.keras.backend.square(tg_z_mean) - tf.keras.backend.exp(tg_z_log_var)\n",
    "    kl_loss2 = 1 + tg_s_log_var - tf.keras.backend.square(tg_s_mean) - tf.keras.backend.exp(tg_s_log_var)\n",
    "    kl_loss3 = 1 + bg_z_log_var - tf.keras.backend.square(bg_z_mean) - tf.keras.backend.exp(bg_z_log_var)\n",
    "\n",
    "    kl_loss1 = tf.keras.backend.sum(kl_loss1, axis=-1)\n",
    "    kl_loss2 = tf.keras.backend.sum(kl_loss2, axis=-1)\n",
    "    kl_loss3 = tf.keras.backend.sum(kl_loss3, axis=-1)\n",
    "\n",
    "    kl_loss = kl_loss1+kl_loss2+kl_loss3\n",
    "    #kl_loss = tf.keras.backend.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    \n",
    "    cvae_loss = tf.keras.backend.mean(reconstruction_loss + beta*kl_loss + gamma*tc_loss + discriminator_loss)\n",
    "    cvae.add_loss(cvae_loss)\n",
    "    \n",
    "    if type(opt)==type(None):\n",
    "        #print('optimizer not specified using ADAM, wroom wroom')\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=learning_rate,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False,name='Adam')\n",
    "        #opt = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, momentum=0.9, epsilon=1e-07, centered=False, name='RMSprop')\n",
    "        #opt = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.1, nesterov=False, name='SGD')\n",
    "\n",
    "\n",
    "    cvae.compile(optimizer=opt,run_eagerly=True)\n",
    "    \n",
    "    return cvae, z_encoder, s_encoder, cvae_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1042  336  336]\n"
     ]
    }
   ],
   "source": [
    "print(data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (336,336,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# params| 21,687,936\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "cvae, z_encoder, s_encoder, cvae_decoder = get_fMRI_CVAE_3D(input_shape=input_shape,\n",
    "                                                             latent_dim=[2,2],\n",
    "                                                             beta=1,\n",
    "                                                             gamma=1,\n",
    "                                                             disentangle=False,\n",
    "                                                             bias=False,\n",
    "                                                             batch_size = batch_size,\n",
    "                                                             kernel_size = 2,\n",
    "                                                             filters = 4,\n",
    "                                                             intermediate_dim = 128,\n",
    "                                                             nlayers = 3,\n",
    "                                                             learning_rate=0.001,\n",
    "                                                             opt=None)\n",
    "\n",
    "num_params = np.sum([np.prod(val.get_shape()) for val in cvae.trainable_weights])\n",
    "print(f'# params| {num_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arrays\n",
    "loss,all_rsas,sigmas,mus,c_sim = [],[],[],[],[]\n",
    "loss_mse,loss_kl,loss_dc,loss_tc = [],[],[],[]\n",
    "s_ranks,z_ranks = [],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-ec82b4228350>:32: MatplotlibDeprecationWarning: Passing non-integers as three-element position specification is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  plt.subplot(nrows,ncols/2,1) # PLOT LOSS\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(5001)):\n",
    "    for i in range(data_loader.n_batches):\n",
    "        \n",
    "        patient_batch,control_batch,batch_df = data_loader.get_batch() # Get a batch\n",
    "        \n",
    "        hist = cvae.train_on_batch([patient_batch,control_batch]) # pass a batch\n",
    "        assert not np.isnan(hist),'loss is NaN - you f**cked up'  # check nothing crashed\n",
    "        loss.append(hist) # keep track of loss\n",
    "        \n",
    "        if all((i==0,np.mod(epoch,25)==0)):\n",
    "            cvae_dashboard() # plot training progress\n",
    "            cvae.save_weights(os.path.join(save_dir,'cvae_weights')) # SAVE WEIGHTS\n",
    "            np.save(os.path.join(save_dir,'cvae_loss.npy'),np.array(loss)) # Save loss\n",
    "            #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae.summary(line_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
