{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98520ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_models import *\n",
    "from helper_funcs import *\n",
    "\n",
    "import numpy as np\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32e4dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e1e80dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/ABIDE_df2.csv')\n",
    "df = df.iloc[~pd.isna(df['bids_folder']).values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7256dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../Assets/fc_mats_32smooth_new/'\n",
    "files = [file for file in os.listdir(data_dir) if file.endswith('.npy')]\n",
    "files.sort()\n",
    "subs = df['bids_folder'].values\n",
    "patients = df['DX_GROUP'].values==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c39f6781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CVAE_2021-10-20 17:33:17.849560',\n",
       " 'CVAE_2021-10-20 17:56:56.023610',\n",
       " 'CVAE_2021-10-21 10:22:04.795354',\n",
       " 'CVAE_2021-10-21 10:27:09.461934',\n",
       " 'CVAE_2021-10-21 10:31:56.636975']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = [w for w in os.listdir('../Assets/tf_weights/') if w.startswith('CVAE')]\n",
    "weights.sort()\n",
    "weights[-5::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a4e0db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysis_name = 'CVAE_2021-09-15 14:03:53.826090'\n",
    "#analysis_name = 'CVAE_2021-10-07 11:03:38.204240'\n",
    "#analysis_name = 'CVAE_2021-10-06 17:30:12.802507'\n",
    "analysis_name = 'CVAE_2021-10-20 16:46:49.014573'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d979911",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = (len(df),32,32,32,51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1db78646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from scipy.special import expit\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import mse\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_fMRI_CVAE_4D(input_shape=(48,48,48,51),\n",
    "                     latent_dim=[2,2],\n",
    "                     beta=1,\n",
    "                     disentangle=False,\n",
    "                     gamma=1,\n",
    "                     bias=True,\n",
    "                     batch_size = 32,\n",
    "                     kernel_size = 3,\n",
    "                     filters = 16,\n",
    "                     intermediate_dim = 128,\n",
    "                     nlayers = 2,\n",
    "                     learning_rate=0.001,\n",
    "                     opt=None):\n",
    "    \n",
    "    \n",
    "    ndim_bg = latent_dim[0]\n",
    "    ndim_sl = latent_dim[1]\n",
    "    \n",
    "    image_size, _, _, channels = input_shape\n",
    "\n",
    "    kernel_regularizer=regularizers.l2(.0001)\n",
    "\n",
    "    # build encoder model\n",
    "    tg_inputs = Input(shape=input_shape, name='tg_inputs')\n",
    "    bg_inputs = Input(shape=input_shape, name='bg_inputs')\n",
    "\n",
    "    # generate latent vector Q(z|X)\n",
    "    z_h_layer = Dense(intermediate_dim, activation='relu', use_bias=bias,kernel_regularizer=kernel_regularizer)\n",
    "    z_mean_layer = Dense(ndim_bg, name='z_mean', use_bias=bias,kernel_regularizer=kernel_regularizer)\n",
    "    z_log_var_layer = Dense(ndim_bg, name='z_log_var', use_bias=bias,kernel_regularizer=kernel_regularizer)\n",
    "    z_layer = Lambda(sampling, output_shape=(ndim_bg,), name='z')\n",
    "\n",
    "    def z_encoder_func(inputs):\n",
    "        z_h = inputs\n",
    "        #z_h = z_conv1(z_h)\n",
    "        #z_h = z_conv2(z_h)\n",
    "        \n",
    "        these_filters = filters\n",
    "        for i in range(nlayers):\n",
    "            these_filters *= 2\n",
    "            #print(these_filters)\n",
    "            z_h = Conv3D(filters=these_filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    activation='relu',\n",
    "                    strides=2,\n",
    "                    padding='same',\n",
    "                    use_bias=bias,\n",
    "                    kernel_regularizer=kernel_regularizer)(z_h)\n",
    "        \n",
    "        # shape info needed to build decoder model\n",
    "        shape = K.int_shape(z_h)\n",
    "        z_h = Flatten()(z_h)\n",
    "        z_h = z_h_layer(z_h)\n",
    "        z_mean =  z_mean_layer(z_h)\n",
    "        z_log_var =  z_log_var_layer(z_h)\n",
    "        z = z_layer([z_mean, z_log_var])\n",
    "        return z_mean, z_log_var, z, shape\n",
    "\n",
    "    tg_z_mean, tg_z_log_var, tg_z, shape_z = z_encoder_func(tg_inputs)\n",
    "\n",
    "    # generate latent vector Q(z|X)\n",
    "    s_h_layer = Dense(intermediate_dim, activation='relu', use_bias=bias,kernel_regularizer=kernel_regularizer)\n",
    "    s_mean_layer = Dense(ndim_sl, name='s_mean', use_bias=bias,kernel_regularizer=kernel_regularizer)\n",
    "    s_log_var_layer = Dense(ndim_sl, name='s_log_var', use_bias=bias,kernel_regularizer=kernel_regularizer)\n",
    "    s_layer = Lambda(sampling, output_shape=(ndim_sl,), name='s')\n",
    "\n",
    "    def s_encoder_func(inputs):\n",
    "        s_h = inputs\n",
    "\n",
    "        these_filters = filters\n",
    "        for i in range(nlayers):\n",
    "            these_filters *= 2\n",
    "            s_h = Conv3D(filters=these_filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    activation='relu',\n",
    "                    strides=2,\n",
    "                    use_bias=bias,\n",
    "                    kernel_regularizer=kernel_regularizer,\n",
    "                    padding='same')(s_h)\n",
    "        \n",
    "        # shape info needed to build decoder model\n",
    "        shape = K.int_shape(s_h)\n",
    "        s_h = Flatten()(s_h)\n",
    "        s_h = s_h_layer(s_h)\n",
    "        s_mean =  s_mean_layer(s_h)\n",
    "        s_log_var =  s_log_var_layer(s_h)\n",
    "        s = s_layer([s_mean, s_log_var])\n",
    "        return s_mean, s_log_var, s, shape\n",
    "\n",
    "    tg_s_mean, tg_s_log_var, tg_s, shape_s = s_encoder_func(tg_inputs)\n",
    "    #bg_s_mean, bg_s_log_var, bg_s, _ = s_encoder_func(bg_inputs) # this is what they had \n",
    "    bg_z_mean, bg_z_log_var, bg_z, _ = z_encoder_func(bg_inputs) # Aidas and Stefano team hax\n",
    "\n",
    "\n",
    "      # instantiate encoder models\n",
    "    z_encoder = tf.keras.models.Model(tg_inputs, [tg_z_mean, tg_z_log_var, tg_z], name='z_encoder')\n",
    "    s_encoder = tf.keras.models.Model(tg_inputs, [tg_s_mean, tg_s_log_var, tg_s], name='s_encoder')\n",
    "\n",
    "\n",
    "      # build decoder model\n",
    "    latent_inputs = Input(shape=(ndim_bg+ndim_sl,), name='z_sampling')\n",
    "\n",
    "    x = Dense(intermediate_dim, activation='relu', use_bias=bias,kernel_regularizer=kernel_regularizer)(latent_inputs)\n",
    "    x = Dense(shape_z[1] * shape_z[2] * shape_z[3] * shape_z[4], activation='relu', use_bias=bias,kernel_regularizer=kernel_regularizer)(x)\n",
    "    x = Reshape((shape_z[1], shape_z[2], shape_z[3],shape_z[4]))(x)\n",
    "\n",
    "    these_filters = filters*(2**nlayers)/2\n",
    "    for i in range(nlayers-1):\n",
    "        x = Conv3DTranspose(filters=these_filters,\n",
    "                          kernel_size=kernel_size,\n",
    "                          activation='relu',\n",
    "                          strides=2,\n",
    "                          use_bias=bias,\n",
    "                          kernel_regularizer=kernel_regularizer,\n",
    "                          padding='same')(x)\n",
    "        these_filters //= 2\n",
    "\n",
    "    outputs = Conv3DTranspose(filters=channels,\n",
    "                            kernel_size=kernel_size,\n",
    "                            activation='sigmoid',\n",
    "                            padding='same',\n",
    "                            strides=2,\n",
    "                            use_bias=bias,\n",
    "                            kernel_regularizer=kernel_regularizer,\n",
    "                            name='decoder_output')(x)\n",
    "\n",
    "    # instantiate decoder model\n",
    "    cvae_decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "      # decoder.summary()\n",
    "\n",
    "    def zeros_like(x):\n",
    "        return tf.zeros_like(x)\n",
    "\n",
    "    tg_outputs = cvae_decoder(tf.keras.layers.concatenate([tg_z, tg_s], -1))\n",
    "    zeros = tf.keras.layers.Lambda(zeros_like)(tg_s)\n",
    "\n",
    "    bg_outputs = cvae_decoder(tf.keras.layers.concatenate([bg_z, zeros], -1)) # Aidas look into this, is this correct\n",
    "\n",
    " #   fg_outputs = cvae_decoder(tf.keras.layers.concatenate([tg_z, zeros], -1))\n",
    "\n",
    "    # instantiate VAE model\n",
    "    cvae = tf.keras.models.Model(inputs=[tg_inputs, bg_inputs], \n",
    "                              outputs=[tg_outputs, bg_outputs], \n",
    "                              name='contrastive_vae')\n",
    "\n",
    "#     cvae_fg = tf.keras.models.Model(inputs=tg_inputs, \n",
    "#                                   outputs=fg_outputs, \n",
    "#                                   name='contrastive_vae_fg')\n",
    "\n",
    "    if disentangle:\n",
    "        discriminator = Dense(1, activation='sigmoid')\n",
    "\n",
    "        z1 = Lambda(lambda x: x[:int(batch_size/2),:])(tg_z)\n",
    "        z2 = Lambda(lambda x: x[int(batch_size/2):,:])(tg_z)\n",
    "        s1 = Lambda(lambda x: x[:int(batch_size/2),:])(tg_s)\n",
    "        s2 = Lambda(lambda x: x[int(batch_size/2):,:])(tg_s)\n",
    "\n",
    "        q_bar = tf.keras.layers.concatenate(\n",
    "          [tf.keras.layers.concatenate([s1, z2], axis=1),\n",
    "          tf.keras.layers.concatenate([s2, z1], axis=1)],\n",
    "          axis=0)\n",
    "\n",
    "        q = tf.keras.layers.concatenate(\n",
    "          [tf.keras.layers.concatenate([s1, z1], axis=1),\n",
    "          tf.keras.layers.concatenate([s2, z2], axis=1)],\n",
    "          axis=0)\n",
    "\n",
    "        q_bar_score = (discriminator(q_bar)+.1) *.85 # +.1 * .85 so that it's 0<x<1\n",
    "        q_score = (discriminator(q)+.1) *.85 \n",
    "        tc_loss = K.log(q_score / (1 - q_score)) \n",
    "        discriminator_loss = - K.log(q_score) - K.log(1 - q_bar_score)\n",
    "    else:\n",
    "        tc_loss = 0\n",
    "        discriminator_loss = 0\n",
    "\n",
    "\n",
    "    reconstruction_loss = tf.keras.losses.mse(K.flatten(tg_inputs), K.flatten(tg_outputs)) \n",
    "    reconstruction_loss += tf.keras.losses.mse(K.flatten(bg_inputs), K.flatten(bg_outputs)) \n",
    "    reconstruction_loss *= input_shape[0] * input_shape[1] * input_shape[2] * input_shape[3]\n",
    "\n",
    "\n",
    "\n",
    "    kl_loss1 = 1 + tg_z_log_var - tf.keras.backend.square(tg_z_mean) - tf.keras.backend.exp(tg_z_log_var)\n",
    "    kl_loss2 = 1 + tg_s_log_var - tf.keras.backend.square(tg_s_mean) - tf.keras.backend.exp(tg_s_log_var)\n",
    "    kl_loss3 = 1 + bg_z_log_var - tf.keras.backend.square(bg_z_mean) - tf.keras.backend.exp(bg_z_log_var)\n",
    "\n",
    "    kl_loss1 = tf.keras.backend.sum(kl_loss1, axis=-1)\n",
    "    kl_loss2 = tf.keras.backend.sum(kl_loss2, axis=-1)\n",
    "    kl_loss3 = tf.keras.backend.sum(kl_loss3, axis=-1)\n",
    "\n",
    "    kl_loss = kl_loss1+kl_loss2+kl_loss3\n",
    "    #kl_loss = tf.keras.backend.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "\n",
    "    # kl_loss = 1 + tg_z_log_var - tf.keras.backend.square(tg_z_mean) - tf.keras.backend.exp(tg_z_log_var)\n",
    "    # kl_loss += 1 + tg_s_log_var - tf.keras.backend.square(tg_s_mean) - tf.keras.backend.exp(tg_s_log_var)\n",
    "    # kl_loss += 1 + bg_z_log_var - tf.keras.backend.square(bg_z_mean) - tf.keras.backend.exp(bg_z_log_var)\n",
    "    # kl_loss = tf.keras.backend.sum(kl_loss, axis=-1)\n",
    "    # kl_loss *= -0.5\n",
    "    \n",
    "    \n",
    "    #print(f'reconstruction loss {reconstruction_loss}')\n",
    "    #print(f'kl_loss loss {kl_loss}')\n",
    "    #print(f'tc_loss loss {tc_loss}')\n",
    "    #print(f'discriminator_loss loss {discriminator_loss}')\n",
    "    \n",
    "    cvae_loss = tf.keras.backend.mean(reconstruction_loss + beta*kl_loss + gamma*tc_loss + discriminator_loss)\n",
    "    cvae.add_loss(cvae_loss)\n",
    "    \n",
    "    if type(opt)==type(None):\n",
    "        #print('optimizer not specified using ADAM, wroom wroom')\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=learning_rate,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False,name='Adam')\n",
    "    \n",
    "#     opt = tf.keras.optimizers.SGD(\n",
    "#     learning_rate=0.01, momentum=0.0, nesterov=False, name='SGD')\n",
    "\n",
    "    #opt = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, momentum=0.9, epsilon=1e-07, centered=False, name='RMSprop')\n",
    "    \n",
    "    #cvae.compile(optimizer='rmsprop',run_eagerly=True)\n",
    "    cvae.compile(optimizer=opt,run_eagerly=True)\n",
    "    \n",
    "\n",
    "    #return cvae, cvae_fg, z_encoder, s_encoder, cvae_decoder\n",
    "    return cvae, z_encoder, s_encoder, cvae_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2af46e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# params| 5,098,724\n"
     ]
    }
   ],
   "source": [
    "#import make_models;reload(make_models);from make_models import *\n",
    "batch_size = 16\n",
    "latent_dim=[128,16]\n",
    "cvae, z_encoder, s_encoder, cvae_decoder = get_fMRI_CVAE_4D(input_shape=tuple(data_size[1::]),\n",
    "                                                             latent_dim=latent_dim,\n",
    "                                                             beta=.001,\n",
    "                                                             gamma=1,\n",
    "                                                             disentangle=True,\n",
    "                                                             bias=True,\n",
    "                                                             batch_size = batch_size,\n",
    "                                                             kernel_size = 3,\n",
    "                                                             filters = 8,\n",
    "                                                             intermediate_dim = 256,\n",
    "                                                             nlayers = 5,\n",
    "                                                             learning_rate=0.001,\n",
    "                                                             opt=None)\n",
    "\n",
    "num_params = np.sum([np.prod(val.get_shape()) for val in cvae.trainable_weights])\n",
    "print(f'# params| {num_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d9f9042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x155496d7bd30>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvae.load_weights(os.path.join('../Assets/tf_weights/',analysis_name,'cvae_weights'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e6237c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 10\n",
    "nsubs = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f438551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_arr = np.zeros((nsamples,nsubs,latent_dim[0]))\n",
    "sl_arr = np.zeros((nsamples,nsubs,latent_dim[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ffb0873",
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_arr_mu = np.zeros((nsubs,latent_dim[0]))\n",
    "sl_arr_mu = np.zeros((nsubs,latent_dim[1]))\n",
    "\n",
    "bg_arr_sigma = np.zeros((nsubs,latent_dim[0]))\n",
    "sl_arr_sigma = np.zeros((nsubs,latent_dim[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7fc7277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1048/1048 [14:34<00:00,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "for s in tqdm(range(nsubs)):\n",
    "    arr = np.load(os.path.join(data_dir,subs[s]+'.npy'))\n",
    "    arr = arr/2\n",
    "    arr = arr[np.newaxis,:,:,:,:]\n",
    "    \n",
    "    vec_s = s_encoder.predict(arr)\n",
    "    vec_z = z_encoder.predict(arr)\n",
    "    \n",
    "    bg_arr_mu[s,:] = vec_z[0]\n",
    "    bg_arr_sigma[s,:] = vec_z[1]\n",
    "    \n",
    "    sl_arr_mu[s,:] = vec_s[0]\n",
    "    sl_arr_sigma[s,:] = vec_s[1]\n",
    "    \n",
    "    for i in range(nsamples):\n",
    "        vec_s = s_encoder.predict(arr)\n",
    "        vec_z = z_encoder.predict(arr)\n",
    "        bg_arr[i,s,:] = vec_z[2]\n",
    "        sl_arr[i,s,:] = vec_s[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51def053",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vecs = dict()\n",
    "latent_vecs['subs'] = subs\n",
    "latent_vecs['BG_ABIDE'] = bg_arr\n",
    "latent_vecs['SL_ABIDE'] = sl_arr\n",
    "\n",
    "latent_vecs['mu_BG_ABIDE'] = bg_arr_mu\n",
    "latent_vecs['mu_SL_ABIDE'] = sl_arr_mu\n",
    "\n",
    "latent_vecs['sigma_BG_ABIDE'] = bg_arr_sigma\n",
    "latent_vecs['sigma_SL_ABIDE'] = sl_arr_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2057345b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/latent_vecs/latent_vecs_CVAE_2021-10-20 16:46:49.014573\n"
     ]
    }
   ],
   "source": [
    "ofn = os.path.join('../Data/latent_vecs/','latent_vecs_'+analysis_name)\n",
    "pickle.dump(latent_vecs,open(ofn,'wb'))\n",
    "print(ofn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e64525bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.path.join('../Data/latent_vecs/','latent_vecs_'+analysis_name+'_sigma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e139020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cea954b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a62919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0d15a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d729a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cvae_decoder.predict(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe7d4065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir = '../Assets/fc_mats_32smooth_new'\n",
    "#data_loader = cvae_data_loader(data_dir=data_dir, df=df, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4944d994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df308b82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994bc445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429f830c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567f4889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba4312b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18225a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8cdec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
