{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff76b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_models import *\n",
    "from helper_funcs import *\n",
    "\n",
    "import numpy as np\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db9e4341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d13ba0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/ABIDE_df2.csv')\n",
    "df = df.iloc[~pd.isna(df['bids_folder']).values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d4cc646",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../Assets/fc_mats_32smooth_new/'\n",
    "files = [file for file in os.listdir(data_dir) if file.endswith('.npy')]\n",
    "files.sort()\n",
    "subs = df['bids_folder'].values\n",
    "patients = df['DX_GROUP'].values==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b5bac6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CVAE_2021-10-06 08:06:32.222665',\n",
       " 'CVAE_2021-10-06 08:08:11.612788',\n",
       " 'CVAE_2021-10-06 08:35:55.310173',\n",
       " 'CVAE_2021-10-06 09:18:26.408246',\n",
       " 'CVAE_2021-10-06 09:19:00.166747']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = [w for w in os.listdir('../Assets/tf_weights/') if w.startswith('CVAE')]\n",
    "weights.sort()\n",
    "weights[-5::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca23e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysis_name = 'CVAE_2021-09-15 14:03:53.826090'\n",
    "analysis_name = 'CVAE_2021-09-30 17:08:46.471890'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cdf91af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1554966039d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CVAE WEIGHTS\n",
    "\n",
    "batch_size = 32; latent_dim = 32\n",
    "# cvae, z_encoder, s_encoder, cvae_decoder = get_fMRI_CVAE_4D(input_shape=(32, 32, 32, 51),\n",
    "#                                                             latent_dim = latent_dim,\n",
    "#                                                             batch_size = batch_size, \n",
    "#                                                             disentangle = True, \n",
    "#                                                             gamma = 1,\n",
    "#                                                             kernel_size = 3,\n",
    "#                                                             filters = 64,\n",
    "#                                                             intermediate_dim = 128,\n",
    "#                                                             nlayers = 2,\n",
    "#                                                             learning_rate=0.001)\n",
    "\n",
    "cvae, z_encoder, s_encoder, cvae_decoder = get_fMRI_CVAE_4D(input_shape=(32, 32, 32, 51),\n",
    "                                                             latent_dim=32,\n",
    "                                                             beta=1,\n",
    "                                                             gamma=1,\n",
    "                                                             disentangle=True,\n",
    "                                                             bias=True,\n",
    "                                                             batch_size = batch_size,\n",
    "                                                             kernel_size = 3,\n",
    "                                                             filters = 16,\n",
    "                                                             intermediate_dim = 256,\n",
    "                                                             nlayers = 4,\n",
    "                                                             learning_rate=0.001,\n",
    "                                                             opt=None)\n",
    "\n",
    "cvae.load_weights(os.path.join('../Assets/tf_weights/',analysis_name,'cvae_weights'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80ac7d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 10\n",
    "nsubs = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f94025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_arr = np.zeros((nsamples,nsubs,latent_dim))\n",
    "sl_arr = np.zeros((nsamples,nsubs,latent_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aec3e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [13:45<00:00, 82.59s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(nsamples),leave=True):\n",
    "    for s in range(nsubs):\n",
    "        arr = np.load(os.path.join(data_dir,subs[s]+'.npy'))\n",
    "        arr = arr/2\n",
    "        arr = arr[np.newaxis,:,:,:,:]\n",
    "\n",
    "        vec_s = s_encoder.predict(arr)[2]\n",
    "        vec_z = z_encoder.predict(arr)[2]\n",
    "\n",
    "        bg_arr[i,s,:] = vec_z\n",
    "        sl_arr[i,s,:] = vec_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1035ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vecs = dict()\n",
    "latent_vecs['BG_ABIDE'] = bg_arr\n",
    "latent_vecs['SL_ABIDE'] = sl_arr\n",
    "latent_vecs['subs'] = subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c68a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbc2948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b288236b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5840c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081a76c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5353725a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e53ed5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(latent_vecs,open(os.path.join('../Data/latent_vecs/','latent_vecs_'+analysis_name),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04ae9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc9d1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f868c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25806769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d0ce0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31c4fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cvae_decoder.predict(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43412ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir = '../Assets/fc_mats_32smooth_new'\n",
    "#data_loader = cvae_data_loader(data_dir=data_dir, df=df, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f581733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9a8f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdf77ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb557683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b1fe60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb3689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0f37f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb34fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
