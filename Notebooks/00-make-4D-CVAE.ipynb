{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mmfs1/data/aglinska/BC-fMRI-AE/Notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/ABIDE_df.csv')\n",
    "df = df.iloc[~pd.isna(df['bids_folder']).values]\n",
    "data_dir = '../Data/fc_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [file for file in os.listdir(data_dir) if file.endswith('.npz')]\n",
    "files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_file = np.array([os.path.exists(os.path.join(data_dir,sub + '.npz')) for sub in df['bids_folder'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[has_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:44<00:00,  4.47it/s]\n"
     ]
    }
   ],
   "source": [
    "n_subs = 200\n",
    "data = np.zeros((n_subs,61, 73, 61, 51))\n",
    "#for s in tqdm(range(len(df))):\n",
    "for s in tqdm(range(n_subs)):\n",
    "    sub = df['bids_folder'].values[s]\n",
    "    datum = np.load(os.path.join(data_dir,sub + '.npz'))['data']\n",
    "    data[s,:,:,:,:] = datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 61, 73, 61, 51)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1554c9a48040>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[10,:,:,20,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import mse\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "    # Arguments:\n",
    "      args (tensor): mean and log of variance of Q(z|X)\n",
    "    # Returns:\n",
    "      z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.layers.convolutional.Conv3D"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_MRI_VAE_3D(input_shape=(64,64,64,1), latent_dim=2, batch_size = 32, disentangle=False, gamma=1):\n",
    "#TODO: add discriminator loss, see if there is improvement. Perhaps try on shapes dataset if it's easier...\n",
    "k = 48\n",
    "input_shape=(k, k, k,51);latent_dim=2;batch_size = 10;disentangle=False;gamma=1\n",
    "\n",
    "\n",
    "\n",
    "image_size, _, _, channels = input_shape\n",
    "kernel_size = 3\n",
    "filters = 16\n",
    "intermediate_dim = 128\n",
    "epochs = 10\n",
    "nlayers = 2\n",
    "\n",
    "  # VAE model = encoder + decoder\n",
    "  # build encoder model\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = inputs\n",
    "for i in range(nlayers):\n",
    "    filters *= 2\n",
    "    x = Conv3D(filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            activation='relu',\n",
    "            strides=2,\n",
    "            padding='same')(x)\n",
    "\n",
    "# shape info needed to build decoder model\n",
    "shape = K.int_shape(x)\n",
    "\n",
    "# generate latent vector Q(z|X)\n",
    "x = Flatten()(x)\n",
    "x = Dense(intermediate_dim, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "# use reparameterization trick to push the sampling out as input\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "# instantiate encoder model\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "\n",
    "# build decoder model\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "x = Dense(shape[1] * shape[2] * shape[3] * shape[4], activation='relu')(x)\n",
    "x = Reshape((shape[1], shape[2], shape[3],shape[4]))(x)\n",
    "\n",
    "for i in range(nlayers):\n",
    "    x = Conv3DTranspose(filters=filters,\n",
    "                      kernel_size=kernel_size,\n",
    "                      activation='relu',\n",
    "                      strides=2,\n",
    "                      padding='same')(x)\n",
    "    filters //= 2\n",
    "\n",
    "outputs = Conv3DTranspose(filters=51,\n",
    "                        kernel_size=kernel_size,\n",
    "                        activation='sigmoid',\n",
    "                        padding='same',\n",
    "                        name='decoder_output')(x)\n",
    "\n",
    "# instantiate decoder model\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "#     decoder.summary()\n",
    "\n",
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae')\n",
    "\n",
    "if disentangle:\n",
    "    discriminator = Dense(1, activation='sigmoid')\n",
    "\n",
    "    z1 = Lambda(lambda x: x[:int(batch_size/2),:int(latent_dim/2)])(z)\n",
    "    z2 = Lambda(lambda x: x[int(batch_size/2):,:int(latent_dim/2)])(z)\n",
    "    s1 = Lambda(lambda x: x[:int(batch_size/2),int(latent_dim/2):])(z)\n",
    "    s2 = Lambda(lambda x: x[int(batch_size/2):,int(latent_dim/2):])(z)\n",
    "\n",
    "    q_bar = tf.keras.layers.concatenate(\n",
    "      [tf.keras.layers.concatenate([s1, z2], axis=1),\n",
    "      tf.keras.layers.concatenate([s2, z1], axis=1)],\n",
    "      axis=0)\n",
    "    q = tf.keras.layers.concatenate(\n",
    "      [tf.keras.layers.concatenate([s1, z1], axis=1),\n",
    "      tf.keras.layers.concatenate([s2, z2], axis=1)],\n",
    "      axis=0)\n",
    "\n",
    "#         q_bar_score = discriminator(q_bar)\n",
    "#         q_score = discriminator(q)        \n",
    "#         tc_loss = K.log(q_score / (1 - q_score)) \n",
    "\n",
    "    q_bar_score = (discriminator(q_bar)+.1) *.85 # +.1 * .85 so that it's 0<x<1\n",
    "    q_score = (discriminator(q)+.1) *.85 \n",
    "    tc_loss = K.log(q_score / (1 - q_score)) \n",
    "\n",
    "    discriminator_loss = - K.log(q_score) - K.log(1 - q_bar_score)\n",
    "\n",
    "reconstruction_loss = mse(K.flatten(inputs), K.flatten(outputs))\n",
    "reconstruction_loss *= image_size * image_size\n",
    "\n",
    "\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "if disentangle:\n",
    "    vae_loss = K.mean(reconstruction_loss) + K.mean(kl_loss) + gamma * K.mean(tc_loss) + K.mean(discriminator_loss)\n",
    "else:\n",
    "    vae_loss = K.mean(reconstruction_loss) + K.mean(kl_loss)\n",
    "\n",
    "vae.add_loss(vae_loss)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False,name='Adam')\n",
    "\n",
    "#vae.compile(optimizer='rmsprop')\n",
    "vae.compile(optimizer=opt)\n",
    "\n",
    "\n",
    "if disentangle:\n",
    "    vae.metrics_tensors = [reconstruction_loss, kl_loss, tc_loss, discriminator_loss]\n",
    "    #     vae.summary()\n",
    "#    return encoder, decoder, vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 48, 48, 48, 51)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch = np.random.rand(10,k,k,k,51)\n",
    "data_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x154d27980c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x154d279bba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 32, 32, 32, 51)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.predict(encoder.predict(data_batch)[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 61, 73, 61, 51)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:385 call\n        return self._run_internal_graph(\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:3099 call\n        return self._make_op(inputs)\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:3121 _make_op\n        c_op = ops._create_c_op(graph, node_def, inputs, control_inputs=[])\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1815 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 158760960 and 138532830 for '{{node vae/tf_op_layer_SquaredDifference_3/SquaredDifference_3}} = SquaredDifference[T=DT_FLOAT, _cloned=true](vae/tf_op_layer_Reshape_7/Reshape_7, vae/tf_op_layer_Reshape_6/Reshape_6)' with input shapes: [158760960], [138532830].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-65e4c77d9a02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                                     class_weight)\n\u001b[1;32m   1694\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 696\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    697\u001b[0m             *args, **kwds))\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3065\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:385 call\n        return self._run_internal_graph(\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:3099 call\n        return self._make_op(inputs)\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:3121 _make_op\n        c_op = ops._create_c_op(graph, node_def, inputs, control_inputs=[])\n    /data/aglinska/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1815 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 158760960 and 138532830 for '{{node vae/tf_op_layer_SquaredDifference_3/SquaredDifference_3}} = SquaredDifference[T=DT_FLOAT, _cloned=true](vae/tf_op_layer_Reshape_7/Reshape_7, vae/tf_op_layer_Reshape_6/Reshape_6)' with input shapes: [158760960], [138532830].\n"
     ]
    }
   ],
   "source": [
    "data_batch = data[0:10,:,:,:,:]\n",
    "print(data_batch.shape)\n",
    "vae.train_on_batch(data_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MRI_CCVAE_3D(input_shape=(64,64,64,1), latent_dim=2, beta=1, disentangle=False, gamma=1, bias=True, batch_size = 64):\n",
    "\n",
    "    image_size, _, _, channels = input_shape\n",
    "    kernel_size = 3\n",
    "    filters = 32\n",
    "    intermediate_dim = 128\n",
    "    epochs = 10\n",
    "    nlayers = 2\n",
    "\n",
    "    # build encoder model\n",
    "    tg_inputs = Input(shape=input_shape, name='tg_inputs')\n",
    "    bg_inputs = Input(shape=input_shape, name='bg_inputs')\n",
    "\n",
    "    z_conv1 = Conv3D(filters=filters*2,\n",
    "            kernel_size=kernel_size,\n",
    "            activation='relu',\n",
    "            strides=2,\n",
    "            use_bias=bias,\n",
    "            padding='same')\n",
    "\n",
    "    z_conv2 = Conv3D(filters=filters*4,\n",
    "            kernel_size=kernel_size,\n",
    "            activation='relu',\n",
    "            strides=2,\n",
    "            use_bias=bias,\n",
    "            padding='same')\n",
    "\n",
    "\n",
    "    # generate latent vector Q(z|X)\n",
    "    z_h_layer = Dense(intermediate_dim, activation='relu', use_bias=bias)\n",
    "    z_mean_layer = Dense(latent_dim, name='z_mean', use_bias=bias)\n",
    "    z_log_var_layer = Dense(latent_dim, name='z_log_var', use_bias=bias)\n",
    "    z_layer = Lambda(sampling, output_shape=(latent_dim,), name='z')\n",
    "\n",
    "    def z_encoder_func(inputs):\n",
    "        z_h = inputs\n",
    "        z_h = z_conv1(z_h)\n",
    "        z_h = z_conv2(z_h)\n",
    "        # shape info needed to build decoder model\n",
    "        shape = K.int_shape(z_h)\n",
    "        z_h = Flatten()(z_h)\n",
    "        z_h = z_h_layer(z_h)\n",
    "        z_mean =  z_mean_layer(z_h)\n",
    "        z_log_var =  z_log_var_layer(z_h)\n",
    "        z = z_layer([z_mean, z_log_var])\n",
    "        return z_mean, z_log_var, z, shape\n",
    "\n",
    "    tg_z_mean, tg_z_log_var, tg_z, shape_z = z_encoder_func(tg_inputs)\n",
    "\n",
    "\n",
    "    s_conv1 = Conv3D(filters=filters*2,\n",
    "            kernel_size=kernel_size,\n",
    "            activation='relu',\n",
    "            strides=2,\n",
    "            use_bias=bias,\n",
    "            padding='same')\n",
    "\n",
    "    s_conv2 = Conv3D(filters=filters*4,\n",
    "            kernel_size=kernel_size,\n",
    "            activation='relu',\n",
    "            strides=2,\n",
    "            use_bias=bias,\n",
    "            padding='same')\n",
    "\n",
    "\n",
    "    # generate latent vector Q(z|X)\n",
    "    s_h_layer = Dense(intermediate_dim, activation='relu', use_bias=bias)\n",
    "    s_mean_layer = Dense(latent_dim, name='s_mean', use_bias=bias)\n",
    "    s_log_var_layer = Dense(latent_dim, name='s_log_var', use_bias=bias)\n",
    "    s_layer = Lambda(sampling, output_shape=(latent_dim,), name='s')\n",
    "\n",
    "    def s_encoder_func(inputs):\n",
    "        s_h = inputs\n",
    "        s_h = s_conv1(s_h)\n",
    "        s_h = s_conv2(s_h)\n",
    "        # shape info needed to build decoder model\n",
    "        shape = K.int_shape(s_h)\n",
    "        s_h = Flatten()(s_h)\n",
    "        s_h = s_h_layer(s_h)\n",
    "        s_mean =  s_mean_layer(s_h)\n",
    "        s_log_var =  s_log_var_layer(s_h)\n",
    "        s = s_layer([s_mean, s_log_var])\n",
    "        return s_mean, s_log_var, s, shape\n",
    "\n",
    "    tg_s_mean, tg_s_log_var, tg_s, shape_s = s_encoder_func(tg_inputs)\n",
    "    #bg_s_mean, bg_s_log_var, bg_s, _ = s_encoder_func(bg_inputs) # this is what they had \n",
    "    bg_z_mean, bg_z_log_var, bg_z, _ = z_encoder_func(bg_inputs) # Aidas and Stefano team hax\n",
    "\n",
    "\n",
    "      # instantiate encoder models\n",
    "    z_encoder = tf.keras.models.Model(tg_inputs, [tg_z_mean, tg_z_log_var, tg_z], name='z_encoder')\n",
    "    s_encoder = tf.keras.models.Model(tg_inputs, [tg_s_mean, tg_s_log_var, tg_s], name='s_encoder')\n",
    "\n",
    "\n",
    "      # build decoder model\n",
    "    latent_inputs = Input(shape=(2*latent_dim,), name='z_sampling')\n",
    "\n",
    "    x = Dense(intermediate_dim, activation='relu', use_bias=bias)(latent_inputs)\n",
    "    x = Dense(shape_z[1] * shape_z[2] * shape_z[3] * shape_z[4], activation='relu', use_bias=bias)(x)\n",
    "    x = Reshape((shape_z[1], shape_z[2], shape_z[3],shape_z[4]))(x)\n",
    "\n",
    "    for i in range(nlayers):\n",
    "        x = Conv3DTranspose(filters=filters,\n",
    "                          kernel_size=kernel_size,\n",
    "                          activation='relu',\n",
    "                          strides=2,\n",
    "                          use_bias=bias,\n",
    "                          padding='same')(x)\n",
    "        filters //= 2\n",
    "\n",
    "    outputs = Conv3DTranspose(filters=1,\n",
    "                            kernel_size=kernel_size,\n",
    "                            activation='sigmoid',\n",
    "                            padding='same',\n",
    "                            use_bias=bias,\n",
    "                            name='decoder_output')(x)\n",
    "\n",
    "    # instantiate decoder model\n",
    "    cvae_decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "      # decoder.summary()\n",
    "\n",
    "    def zeros_like(x):\n",
    "        return tf.zeros_like(x)\n",
    "\n",
    "    tg_outputs = cvae_decoder(tf.keras.layers.concatenate([tg_z, tg_s], -1))\n",
    "    zeros = tf.keras.layers.Lambda(zeros_like)(tg_z)\n",
    "\n",
    "    bg_outputs = cvae_decoder(tf.keras.layers.concatenate([bg_z, zeros], -1)) # Aidas look into this, is this correct\n",
    "\n",
    " #   fg_outputs = cvae_decoder(tf.keras.layers.concatenate([tg_z, zeros], -1))\n",
    "\n",
    "    # instantiate VAE model\n",
    "    cvae = tf.keras.models.Model(inputs=[tg_inputs, bg_inputs], \n",
    "                              outputs=[tg_outputs, bg_outputs], \n",
    "                              name='contrastive_vae')\n",
    "\n",
    "#     cvae_fg = tf.keras.models.Model(inputs=tg_inputs, \n",
    "#                                   outputs=fg_outputs, \n",
    "#                                   name='contrastive_vae_fg')\n",
    "\n",
    "    if disentangle:\n",
    "        discriminator = Dense(1, activation='sigmoid')\n",
    "\n",
    "        z1 = Lambda(lambda x: x[:int(batch_size/2),:])(tg_z)\n",
    "        z2 = Lambda(lambda x: x[int(batch_size/2):,:])(tg_z)\n",
    "        s1 = Lambda(lambda x: x[:int(batch_size/2),:])(tg_s)\n",
    "        s2 = Lambda(lambda x: x[int(batch_size/2):,:])(tg_s)\n",
    "\n",
    "        q_bar = tf.keras.layers.concatenate(\n",
    "          [tf.keras.layers.concatenate([s1, z2], axis=1),\n",
    "          tf.keras.layers.concatenate([s2, z1], axis=1)],\n",
    "          axis=0)\n",
    "\n",
    "        q = tf.keras.layers.concatenate(\n",
    "          [tf.keras.layers.concatenate([s1, z1], axis=1),\n",
    "          tf.keras.layers.concatenate([s2, z2], axis=1)],\n",
    "          axis=0)\n",
    "\n",
    "        q_bar_score = (discriminator(q_bar)+.1) *.85 # +.1 * .85 so that it's 0<x<1\n",
    "        q_score = (discriminator(q)+.1) *.85 \n",
    "        tc_loss = K.log(q_score / (1 - q_score)) \n",
    "        discriminator_loss = - K.log(q_score) - K.log(1 - q_bar_score)\n",
    "    else:\n",
    "        tc_loss = 0\n",
    "        discriminator_loss = 0\n",
    "\n",
    "\n",
    "    reconstruction_loss = tf.keras.losses.mse(K.flatten(tg_inputs), K.flatten(tg_outputs)) \n",
    "    reconstruction_loss += tf.keras.losses.mse(K.flatten(bg_inputs), K.flatten(bg_outputs)) \n",
    "    reconstruction_loss *= input_shape[0] * input_shape[1] * input_shape[2] * input_shape[3]\n",
    "\n",
    "\n",
    "    kl_loss = 1 + tg_z_log_var - tf.keras.backend.square(tg_z_mean) - tf.keras.backend.exp(tg_z_log_var)\n",
    "    kl_loss += 1 + tg_s_log_var - tf.keras.backend.square(tg_s_mean) - tf.keras.backend.exp(tg_s_log_var)\n",
    "    kl_loss += 1 + bg_z_log_var - tf.keras.backend.square(bg_z_mean) - tf.keras.backend.exp(bg_z_log_var)\n",
    "    kl_loss = tf.keras.backend.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    \n",
    "    \n",
    "    #print(f'reconstruction loss {reconstruction_loss}')\n",
    "    #print(f'kl_loss loss {kl_loss}')\n",
    "    #print(f'tc_loss loss {tc_loss}')\n",
    "    #print(f'discriminator_loss loss {discriminator_loss}')\n",
    "    \n",
    "    cvae_loss = tf.keras.backend.mean(reconstruction_loss + beta*kl_loss + gamma*tc_loss + discriminator_loss)\n",
    "    cvae.add_loss(cvae_loss)\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False,name='Adam')\n",
    "    \n",
    "#     opt = tf.keras.optimizers.SGD(\n",
    "#     learning_rate=0.01, momentum=0.0, nesterov=False, name='SGD')\n",
    "\n",
    "    #opt = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, momentum=0.9, epsilon=1e-07, centered=False, name='RMSprop')\n",
    "    \n",
    "    #cvae.compile(optimizer='rmsprop',run_eagerly=True)\n",
    "    cvae.compile(optimizer=opt,run_eagerly=True)\n",
    "    \n",
    "\n",
    "    #return cvae, cvae_fg, z_encoder, s_encoder, cvae_decoder\n",
    "    return cvae, z_encoder, s_encoder, cvae_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
